{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom transformers import TrainingArguments, Trainer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 🤗 Hugging Face Datasets Kütüphanesi\n\n### Parametreler\n\n- **`path`**:\n  - Yüklenecek veri setinin yolu veya ismi. Örnek: \"imdb\", \"glue\".\n\n- **`name`**:\n  - Yüklenecek veri setinin alt kümesi. Örnek: \"sst2\" (GLUE için).\n\n- **`data_dir`**:\n  - Veri dosyalarının bulunduğu dizin.\n\n- **`data_files`**:\n  - Yüklenecek veri dosyaları.\n\n- **`split`**:\n  - Veri setinin bölünmesi (örneğin \"train\", \"test\").\n\n- **`cache_dir`**:\n  - Verinin önbelleğe alınacağı dizin.\n\n- **`features`**:\n  - Özelliklerin açıkça belirtildiği yer.\n\n- **`download_config`**:\n  - İndirme yapılandırma ayarları.\n\n- **`download_mode`**:\n  - İndirme modu: \"reuse_dataset_if_exists\", \"reuse_cache_if_exists\", \"force_redownload\".\n\n- **`verification_mode`**:\n  - Veri setinin doğrulama modu.\n\n- **`ignore_verifications`**:\n  - Artık kullanılmıyor, doğrulamaları atlamak için.\n\n- **`keep_in_memory`**:\n  - Eğer True ise, veri seti bellekte tutulur.\n\n- **`save_infos`**:\n  - Eğer True ise, veri seti bilgileri kaydedilir.\n\n- **`revision`**:\n  - Yüklenecek veri setinin versiyonu veya commit ID'si.\n\n- **`token`**:\n  - Private veri setleri için kullanılır, bir token sağlar.\n\n- **`use_auth_token`**:\n  - Artık kullanılmıyor, oturum açma token'ı için.\n\n- **`task`**:\n  - Artık kullanılmıyor, veri seti yükleme görevini belirtmek için.\n\n- **`streaming`**:\n  - Eğer True ise, veri seti akış modunda yüklenir.\n\n- **`num_proc`**:\n  - Çok işlemcili veri işleme için işlemci sayısı.\n\n- **`storage_options`**:\n  - Depolama seçenekleri.\n\n- **`trust_remote_code`**:\n  - Eğer True ise, uzaktan kod çalıştırmaya izin verir.\n\n- **`**config_kwargs`**:\n  - Diğer ek yapılandırma argümanları.\n","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset('Trelis/tiny-shakespeare', split='train')\n\ndataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 🤗 Hugging Face Tokenizer Kütüphanesi\n\n### Parametreler\n\n- **`text`**:\n  - Tokenize edilecek metin veya metinlerin listesi.\n\n- **`text_pair`**:\n  - İkinci bir metin veya metinlerin listesi, çift metinli modeller için kullanılır.\n\n- **`text_target`**:\n  - Hedef metin veya metinlerin listesi (genellikle seq2seq modelleri için kullanılır).\n\n- **`text_pair_target`**:\n  - Hedef ikinci metin veya metinlerin listesi, çift metinli modeller için kullanılır.\n\n- **`add_special_tokens`**:\n  - Özel tokenler ekler (örneğin [CLS], [SEP]). True olması, modeli daha iyi performans gösterir.\n\n- **`padding`**:\n  - Padding stratejisi: True, False, \"longest\", \"max_length\".\n\n- **`truncation`**:\n  - Kesme stratejisi: True, False, \"longest_first\", \"only_first\".\n\n- **`max_length`**:\n  - Maksimum token sayısı. Yüksek değerler daha fazla bilgi taşır ama daha fazla bellek kullanır.\n\n- **`stride`**:\n  - Kesme sırasında kayma boyutu. Uzun metinler için daha küçük değerler kullanışlı olabilir.\n\n- **`is_split_into_words`**:\n  - Eğer True ise, metin kelimelere bölünmüş olarak kabul edilir.\n\n- **`pad_to_multiple_of`**:\n  - Padding boyutunun bir katı olacak şekilde padding ekler.\n\n- **`return_tensors`**:\n  - Döndürülecek tensör tipi: 'pt', 'tf', 'np'.\n\n- **`return_token_type_ids`**:\n  - Eğer True ise, token tipi ID'lerini döndürür.\n\n- **`return_attention_mask`**:\n  - Eğer True ise, attention maskelerini döndürür.\n\n- **`return_overflowing_tokens`**:\n  - Eğer True ise, taşan tokenleri döndürür.\n\n- **`return_special_tokens_mask`**:\n  - Eğer True ise, özel token maskesini döndürür.\n\n- **`return_offsets_mapping`**:\n  - Eğer True ise, offset mapping döndürür.\n\n- **`return_length`**:\n  - Eğer True ise, token uzunluklarını döndürür.\n\n- **`verbose`**:\n  - Eğer True ise, işlem hakkında daha fazla bilgi verir.\n\n- **`**kwargs`**:\n  - Diğer ek argümanlar.\n","metadata":{}},{"cell_type":"code","source":"base_model_name = \"openai-community/gpt2\"\n\ntokenizer = AutoTokenizer.from_pretrained(base_model_name)\n\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def text_tokenizer(text):\n    return tokenizer(\n        text['text'], \n        max_length=128, \n        truncation=True, \n        padding='max_length', \n        return_tensors='pt'\n    )\n\ntrain_data = dataset['train'].map(text_tokenizer, batched=True)\ntest_data = dataset['test'].map(text_tokenizer, batched=True)\nval_data = dataset['validation'].map(text_tokenizer, batched=True)\n\ntrain_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(base_model_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 🤗 Hugging Face TrainingArguments Kütüphanesi\n\n### Parametreler\n\n- **`output_dir`**:\n  - Eğitim sırasında ve sonrasında sonuçların kaydedileceği dizin.\n\n- **`overwrite_output_dir`**:\n  - Eğer True ise, mevcut `output_dir` içeriğini üzerine yazar.\n\n- **`do_train`**:\n  - Eğitim işleminin yapılıp yapılmayacağını belirtir.\n\n- **`do_eval`**:\n  - Değerlendirme işleminin yapılıp yapılmayacağını belirtir.\n\n- **`do_predict`**:\n  - Tahmin işleminin yapılıp yapılmayacağını belirtir.\n\n- **`eval_strategy`**:\n  - Değerlendirme stratejisi: 'no', 'steps' veya 'epoch'.\n\n- **`prediction_loss_only`**:\n  - Eğer True ise, sadece kayıp hesaplanır, tahminler döndürülmez.\n\n- **`per_device_train_batch_size`**:\n  - Her bir cihaz (GPU/CPU) için eğitim batch boyutu.\n\n- **`per_device_eval_batch_size`**:\n  - Her bir cihaz (GPU/CPU) için değerlendirme batch boyutu.\n\n- **`gradient_accumulation_steps`**:\n  - Gradient biriktirme adımları. Yüksek değerler bellek kullanımını azaltır ama eğitim süresini uzatır.\n\n- **`eval_accumulation_steps`**:\n  - Değerlendirme biriktirme adımları. Yüksek değerler bellek kullanımını azaltır ama değerlendirme süresini uzatır.\n\n- **`eval_delay`**:\n  - Eğitim başladıktan sonra ilk değerlendirmenin yapılacağı adım sayısı.\n\n- **`learning_rate`**:\n  - Öğrenme oranı. Yüksek değerler daha hızlı öğrenir ama aşırı öğrenmeye (overfitting) yol açabilir.\n\n- **`weight_decay`**:\n  - Ağırlıkların küçülme oranı. Yüksek değerler modelin genelleme yeteneğini artırabilir ama öğrenme yavaşlar.\n\n- **`adam_beta1`**:\n  - Adam optimizasyon algoritması için beta1 parametresi.\n\n- **`adam_beta2`**:\n  - Adam optimizasyon algoritması için beta2 parametresi.\n\n- **`adam_epsilon`**:\n  - Adam optimizasyon algoritması için epsilon parametresi.\n\n- **`max_grad_norm`**:\n  - Gradientlerin maksimum normu. Büyük değerler modelin stabilitesini artırabilir.\n\n- **`num_train_epochs`**:\n  - Eğitim için epoch sayısı. Yüksek değerler daha fazla öğrenme sağlar ama aşırı öğrenmeye yol açabilir.\n\n- **`max_steps`**:\n  - Maksimum eğitim adım sayısı. -1 ise, tüm epoch'lar tamamlanır.\n\n- **`lr_scheduler_type`**:\n  - Öğrenme oranı zamanlayıcı tipi.\n\n- **`lr_scheduler_kwargs`**:\n  - Öğrenme oranı zamanlayıcısı için ek parametreler.\n\n- **`warmup_ratio`**:\n  - Öğrenme oranı ısınma oranı. Yüksek değerler başlangıçta daha yavaş öğrenme sağlar.\n\n- **`warmup_steps`**:\n  - Öğrenme oranı ısınma adım sayısı. Yüksek değerler başlangıçta daha yavaş öğrenme sağlar.\n\n- **`log_level`**:\n  - Log seviyesi. 'passive', 'info', 'warning', 'error' veya 'critical'.\n\n- **`log_level_replica`**:\n  - Çoklu GPU eğitiminde log seviyesi.\n\n- **`log_on_each_node`**:\n  - Çoklu node eğitiminde her node için loglama yapılır.\n\n- **`logging_dir`**:\n  - TensorBoard logları için dizin.\n\n- **`logging_strategy`**:\n  - Loglama stratejisi: 'no', 'steps' veya 'epoch'.\n\n- **`logging_first_step`**:\n  - Eğer True ise, ilk adımda loglama yapılır.\n\n- **`logging_steps`**:\n  - Kaç adımda bir loglama yapılacağı.\n\n- **`logging_nan_inf_filter`**:\n  - Eğer True ise, NaN ve sonsuz değerler loglanmaz.\n\n- **`save_strategy`**:\n  - Modelin kaydedilme stratejisi: 'no', 'steps' veya 'epoch'.\n\n- **`save_steps`**:\n  - Kaç adımda bir modelin kaydedileceği.\n\n- **`save_total_limit`**:\n  - Maksimum kaç model kaydedileceği.\n\n- **`save_safetensors`**:\n  - Modelin güvenli tensör formatında kaydedilip kaydedilmeyeceği.\n\n- **`save_on_each_node`**:\n  - Eğer True ise, her node'da model kaydedilir.\n\n- **`save_only_model`**:\n  - Eğer True ise, sadece model kaydedilir, optimizer ve lr scheduler kaydedilmez.\n\n- **`restore_callback_states_from_checkpoint`**:\n  - Callback durumlarının checkpoint'ten geri yüklenip yüklenmeyeceği.\n\n- **`no_cuda`**:\n  - Eğer True ise, GPU kullanılmaz.\n\n- **`use_cpu`**:\n  - Eğer True ise, CPU kullanılır.\n\n- **`use_mps_device`**:\n  - Eğer True ise, MacOS Metal Performance Shaders kullanılır.\n\n- **`seed`**:\n  - Rastgelelik için seed değeri.\n\n- **`data_seed`**:\n  - Veri yükleme için seed değeri.\n\n- **`jit_mode_eval`**:\n  - Eğer True ise, PyTorch JIT modu kullanılır.\n\n- **`use_ipex`**:\n  - Eğer True ise, Intel Extension for PyTorch kullanılır.\n\n- **`bf16`**:\n  - Eğer True ise, bfloat16 kullanılır.\n\n- **`fp16`**:\n  - Eğer True ise, float16 kullanılır.\n\n- **`fp16_opt_level`**:\n  - float16 optimizasyon seviyesi.\n\n- **`half_precision_backend`**:\n  - Yarı hassasiyet arka ucu: 'auto', 'amp' veya 'apex'.\n\n- **`bf16_full_eval`**:\n  - Eğer True ise, bfloat16 tam değerlendirme yapılır.\n\n- **`fp16_full_eval`**:\n  - Eğer True ise, float16 tam değerlendirme yapılır.\n\n- **`tf32`**:\n  - Eğer True ise, TensorFloat-32 kullanılır.\n\n- **`local_rank`**:\n  - Çoklu GPU eğitiminde lokal rank.\n\n- **`ddp_backend`**:\n  - DDP backend tipi: 'nccl', 'gloo', 'mpi'.\n\n- **`tpu_num_cores`**:\n  - TPU çekirdek sayısı.\n\n- **`tpu_metrics_debug`**:\n  - TPU metriklerinin debug bilgilerini içerir.\n\n- **`debug`**:\n  - Debug seçeneği: 'underflow_overflow', 'poor_optimization'.\n\n- **`dataloader_drop_last`**:\n  - Eğer True ise, dataloader son batch'i düşürür.\n\n- **`eval_steps`**:\n  - Değerlendirme adım sayısı.\n\n- **`dataloader_num_workers`**:\n  - Dataloader için çalışan sayısı. Yüksek değerler hız artırır ama daha fazla bellek kullanır.\n\n- **`dataloader_prefetch_factor`**:\n  - Dataloader için prefetch faktörü. Yüksek değerler hız artırır ama daha fazla bellek kullanır.\n\n- **`past_index`**:\n  - Geçmiş index.\n\n- **`run_name`**:\n  - Çalışma ismi.\n\n- **`disable_tqdm`**:\n  - Eğer True ise, tqdm progress bar devre dışı bırakılır.\n\n- **`remove_unused_columns`**:\n  - Eğer True ise, kullanılmayan sütunlar veri setinden kaldırılır.\n\n- **`label_names`**:\n  - Label isimleri.\n\n- **`load_best_model_at_end`**:\n  - Eğitim sonunda en iyi modelin yüklenip yüklenmeyeceği.\n\n- **`metric_for_best_model`**:\n  - En iyi modelin seçilmesi için kullanılacak metrik.\n\n- **`greater_is_better`**:\n  - Eğer True ise, metriklerde yüksek değerler daha iyi olarak kabul edilir.\n\n- **`ignore_data_skip`**:\n  - Eğer True ise, veri atlamaları göz ardı edilir.\n\n- **`fsdp`**:\n  - Fully Sharded Data Parallel ayarları.\n\n- **`fsdp_min_num_params`**:\n  - Fully Sharded Data Parallel için minimum parametre sayısı.\n\n- **`fsdp_config`**:\n  - Fully Sharded Data Parallel için ek ayarlar.\n\n- **`fsdp_transformer_layer_cls_to_wrap`**:\n  - Fully Sharded Data Parallel için transformer layer sınıfı.\n\n- **`accelerator_config`**:\n  - Accelerator için ek ayarlar.\n\n- **`deepspeed`**:\n  - DeepSpeed yapılandırması.\n\n- **`label_smoothing_factor`**:\n  - Label smoothing faktörü.\n\n- **`optim`**:\n  - Optimizasyon algoritması.\n\n- **`optim_args`**:\n  - Optimizasyon algoritması için ek argümanlar.\n\n- **`adafactor`**:\n  - Eğer True ise, Adafactor optimizasyon algoritması kullanılır.\n\n- **`group_by_length`**:\n  - Eğer True ise, input uzunluğuna göre gruplanır.\n\n- **`length_column_name`**:\n  - Uzunluk sütunu ismi.\n\n- **`report_to`**:\n  - Raporlama platformları (örneğin 'wandb').\n\n- **`ddp_find_unused_parameters`**:\n  - DDP'de kullanılmayan parametrelerin bulunması.\n\n- **`ddp_bucket_cap_mb`**:\n  - DDP bucket kapasitesi.\n\n- **`ddp_broadcast_buffers`**:\n  - DDP broadcast buffer'ları.\n\n- **`dataloader_pin_memory`**:\n  - Dataloader için bellek pinleme.\n\n- **`dataloader_persistent_workers`**:\n  - Dataloader için kalıcı çalışanlar.\n\n- **`skip_memory_metrics`**:\n  - Eğer True ise, bellek metrikleri atlanır.\n\n- **`use_legacy_prediction_loop`**:\n  - Eğer True ise, eski tahmin döngüsü kullanılır.\n\n- **`push_to_hub`**:\n  - Eğer True ise, model Hugging Face Hub'a itilir.\n\n- **`resume_from_checkpoint`**:\n  - Checkpoint'ten devam edilir.\n\n- **`hub_model_id`**:\n  - Hugging Face Hub model ID.\n\n- **`hub_strategy`**:\n  - Hub stratejisi.\n\n- **`hub_token`**:\n  - Hugging Face Hub token.\n\n- **`hub_private_repo`**:\n  - Eğer True ise, özel repo kullanılır.\n\n- **`hub_always_push`**:\n  - Eğer True ise, her zaman Hub'a itilir.\n\n- **`gradient_checkpointing`**:\n  - Eğer True ise, gradient checkpointing yapılır.\n\n- **`gradient_checkpointing_kwargs`**:\n  - Gradient checkpointing için ek argümanlar.\n\n- **`include_inputs_for_metrics`**:\n  - Eğer True ise, değerlendirme metrikleri için inputlar da dahil edilir.\n\n- **`eval_do_concat_batches`**:\n  - Eğer True ise, değerlendirme batch'leri birleştirilir.\n\n- **`fp16_backend`**:\n  - float16 arka ucu.\n\n- **`evaluation_strategy`**:\n  - Değerlendirme stratejisi: 'no', 'steps' veya 'epoch'.\n\n- **`push_to_hub_model_id`**:\n  - Hub model ID.\n\n- **`push_to_hub_organization`**:\n  - Hub organizasyon ID.\n\n- **`push_to_hub_token`**:\n  - Hub token.\n\n- **`mp_parameters`**:\n  - Model paralel parametreler.\n\n- **`auto_find_batch_size`**:\n  - Eğer True ise, batch boyutu otomatik bulunur.\n\n- **`full_determinism`**:\n  - Eğer True ise, deterministik eğitim yapılır.\n\n- **`torchdynamo`**:\n  - TorchDynamo kullanımı.\n\n- **`ray_scope`**:\n  - Ray scope.\n\n- **`ddp_timeout`**:\n  - DDP timeout süresi.\n\n- **`torch_compile`**:\n  - Eğer True ise, Torch compile kullanılır.\n\n- **`torch_compile_backend`**:\n  - Torch compile backend.\n\n- **`torch_compile_mode`**:\n  - Torch compile modu.\n\n- **`dispatch_batches`**:\n  - Batch dispatching.\n\n- **`split_batches`**:\n  - Batch splitting.\n\n- **`include_tokens_per_second`**:\n  - Eğer True ise, saniye başına token sayısı dahil edilir.\n\n- **`include_num_input_tokens_seen`**:\n  - Eğer True ise, görülen input token sayısı dahil edilir.\n\n- **`neftune_noise_alpha`**:\n  - Neptune noise alpha.\n\n- **`optim_target_modules`**:\n  - Optimizasyon hedef modüller.\n\n- **`batch_eval_metrics`**:\n  - Eğer True ise, batch değerlendirme metrikleri hesaplanır.\n","metadata":{}},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=1,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    hub_model_id='gpt2-wikitext-text-generation'\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 🤗 Hugging Face Trainer Kütüphanesi\n\n### Parametreler\n\n- **`model`**:\n  - Eğitim ve değerlendirme için kullanılacak model.\n\n- **`args`**:\n  - Eğitim argümanları, `TrainingArguments` sınıfı ile oluşturulur.\n\n- **`data_collator`**:\n  - Veriyi toplamak için kullanılan data collator.\n\n- **`train_dataset`**:\n  - Eğitim için kullanılacak veri seti.\n\n- **`eval_dataset`**:\n  - Değerlendirme için kullanılacak veri seti.\n\n- **`tokenizer`**:\n  - Metin verilerini modelin anlayabileceği sayısal değerlere dönüştürür.\n\n- **`model_init`**:\n  - Modelin başlatılması için kullanılacak fonksiyon.\n\n- **`compute_metrics`**:\n  - Değerlendirme metriklerini hesaplamak için kullanılacak fonksiyon.\n\n- **`callbacks`**:\n  - Eğitim sürecini izlemek ve kontrol etmek için kullanılacak callback listesi.\n\n- **`optimizers`**:\n  - Optimizasyon algoritması ve öğrenme oranı zamanlayıcısı.\n\n- **`preprocess_logits_for_metrics`**:\n  - Metrik hesaplama için logits'i ön işleme fonksiyonu.\n","metadata":{}},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=val_data\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ac4525a27cdcb34c068674c5fed00841eb0d9f4c","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\n# Login to Hugging Face account\nnotebook_login()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-06-19T18:05:28.944443Z","iopub.execute_input":"2024-06-19T18:05:28.944962Z","iopub.status.idle":"2024-06-19T18:05:29.248581Z","shell.execute_reply.started":"2024-06-19T18:05:28.944934Z","shell.execute_reply":"2024-06-19T18:05:29.247736Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f90182cd59294195bde8a458007b2587"}},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\nfrom datasets import load_dataset\n\n# Load dataset\ndataset = load_dataset('Trelis/tiny-shakespeare', split='train')\n\n# Load tokenizer and model\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\nmodel = GPT2LMHeadModel.from_pretrained('gpt2')\nmodel.to('cuda:0')\n# Set pad token\ntokenizer.pad_token = tokenizer.eos_token\n\n# Tokenize function\ndef tokenize_function(examples):\n    inputs = tokenizer(examples['Text'], truncation=True, padding='max_length', max_length=128)\n    inputs['labels'] = inputs['input_ids'].copy()\n    return inputs\n\n# Tokenize dataset\ntokenized_dataset = dataset.map(tokenize_function, batched=True)\n\n# Training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    evaluation_strategy=\"no\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=2,\n    do_eval=False,\n    num_train_epochs=1,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    push_to_hub=True,\n    hub_model_id='gpt2-wikitext-text-generation',\n    hub_strategy=\"end\",\n)\n\n# Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset,\n)\n\n# Train model\ntrainer.train()\n\n# Move model to device\nmodel = trainer.model\nmodel.to('cuda:0')\n\n# Input texts\ninput_texts = [\n    \"To be, or not to be, that is the question:\",\n    \"All the world's a stage, and all the men and women merely players:\"\n]\n\n# Generate text\ntext = input_texts[0]\ninputs = tokenizer(text, return_tensors='pt').to(device)\n\nprompt_text = \"Once upon a time\"\ninput_ids = tokenizer.encode(prompt_text, return_tensors='pt').to(device)\n\noutput = model.generate(\n    input_ids,\n    max_length=100,\n    num_return_sequences=1,\n    no_repeat_ngram_size=2,\n    early_stopping=True\n)\n\ngenerated_text = tokenizer.decode(output[0], skip_special_tokens=True)\nprint(generated_text)","metadata":{"execution":{"iopub.status.busy":"2024-06-19T18:05:35.981970Z","iopub.execute_input":"2024-06-19T18:05:35.982346Z","iopub.status.idle":"2024-06-19T18:06:46.166879Z","shell.execute_reply.started":"2024-06-19T18:05:35.982316Z","shell.execute_reply":"2024-06-19T18:06:46.165315Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-06-19 18:05:43.283789: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-19 18:05:43.283920: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-19 18:05:43.416533: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/497 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63c86b30fe9e4a78aed11663b7008baa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.22M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a62c16ae762d462f8060c16a82c1da3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/119k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3b305886911418580e4304dbae5e5c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/472 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57bcb8032f954c68b69a304c84565e15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/49 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a827b34349e14cc49611e675b3443a43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acd2cc5d85474d088c39578b67167776"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"800aa21e14a045f9b16c7cadf861368f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e727bb94aaf749f3969f8fea1e3e5277"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56a4b9900f34499fb43c3a6f5b04c360"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46b68173ae034c108d1405e4a2b76536"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3573273891824e28ba0031d57916e1e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f1eb1b8a044412fa3ebb9a653b4f031"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/472 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e111ec578d14c769c69853ec25a040e"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240619_180624-rjvfifv3</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/fawern/huggingface/runs/rjvfifv3' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/fawern/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/fawern/huggingface' target=\"_blank\">https://wandb.ai/fawern/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/fawern/huggingface/runs/rjvfifv3' target=\"_blank\">https://wandb.ai/fawern/huggingface/runs/rjvfifv3</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 47\u001b[0m\n\u001b[1;32m     40\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     41\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     42\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     43\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtokenized_dataset,\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Move model to device\u001b[39;00m\n\u001b[1;32m     50\u001b[0m model \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mmodel\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1876\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1873\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1874\u001b[0m     \u001b[38;5;66;03m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[1;32m   1875\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39mdisable_progress_bars()\n\u001b[0;32m-> 1876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1877\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1880\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1883\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2216\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2216\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2219\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2220\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2221\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2222\u001b[0m ):\n\u001b[1;32m   2223\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2224\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3241\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3238\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs)\n\u001b[1;32m   3240\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[0;32m-> 3241\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3244\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/memory.py:159\u001b[0m, in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Releases all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 159\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"],"ename":"RuntimeError","evalue":"CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}