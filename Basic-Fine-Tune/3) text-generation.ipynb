{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-26T14:37:49.843754Z","iopub.status.busy":"2024-06-26T14:37:49.843469Z","iopub.status.idle":"2024-06-26T14:37:49.854642Z","shell.execute_reply":"2024-06-26T14:37:49.853609Z","shell.execute_reply.started":"2024-06-26T14:37:49.843728Z"},"trusted":true},"outputs":[],"source":["# warnings kÃ¼tÃ¼phanesi uyarÄ±larÄ± kapatmak iÃ§in kullanÄ±lÄ±r\n","import warnings \n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T14:37:50.202913Z","iopub.status.busy":"2024-06-26T14:37:50.202615Z","iopub.status.idle":"2024-06-26T14:37:51.249853Z","shell.execute_reply":"2024-06-26T14:37:51.248932Z","shell.execute_reply.started":"2024-06-26T14:37:50.202887Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Wed Jun 26 14:37:51 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","|   1  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\n","| N/A   44C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["# GPU ve CUDA sÃ¼rÃ¼mlerini kontrol etmek iÃ§in kullanÄ±lÄ±r\n","!nvidia-smi"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T14:38:26.320969Z","iopub.status.busy":"2024-06-26T14:38:26.320549Z","iopub.status.idle":"2024-06-26T14:38:26.326042Z","shell.execute_reply":"2024-06-26T14:38:26.324794Z","shell.execute_reply.started":"2024-06-26T14:38:26.320939Z"},"trusted":true},"outputs":[],"source":["from datasets import load_dataset\n","\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","from transformers import TrainingArguments, Trainer\n","\n","import torch "]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T14:38:43.290982Z","iopub.status.busy":"2024-06-26T14:38:43.290324Z","iopub.status.idle":"2024-06-26T14:38:43.296976Z","shell.execute_reply":"2024-06-26T14:38:43.295890Z","shell.execute_reply.started":"2024-06-26T14:38:43.290947Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["datasets version: 2.19.2\n","transformers version: 4.41.2\n","torch version: 2.1.2\n"]}],"source":["print(\"datasets version: 2.19.2\")\n","print(\"transformers version: 4.41.2\")\n","print(\"torch version: 2.1.2\")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T21:05:59.469437Z","iopub.status.busy":"2024-06-25T21:05:59.469084Z","iopub.status.idle":"2024-06-25T21:05:59.493270Z","shell.execute_reply":"2024-06-25T21:05:59.492002Z","shell.execute_reply.started":"2024-06-25T21:05:59.469411Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"78f4959d59f2467f91e101968ea21d12","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"]},"metadata":{},"output_type":"display_data"}],"source":["from huggingface_hub import notebook_login\n","\n","## Huggingface token, https://huggingface.co/settings/profile\n","notebook_login()"]},{"cell_type":"markdown","metadata":{},"source":["## ðŸ¤— Hugging Face Datasets KÃ¼tÃ¼phanesi\n","\n","### Parametreler\n","\n","- **`path`**:\n","  - YÃ¼klenecek veri setinin yolu veya ismi. Ã–rnek: \"imdb\", \"glue\".\n","\n","- **`name`**:\n","  - YÃ¼klenecek veri setinin alt kÃ¼mesi. Ã–rnek: \"sst2\" (GLUE iÃ§in).\n","\n","- **`data_dir`**:\n","  - Veri dosyalarÄ±nÄ±n bulunduÄŸu dizin.\n","\n","- **`data_files`**:\n","  - YÃ¼klenecek veri dosyalarÄ±.\n","\n","- **`split`**:\n","  - Veri setinin bÃ¶lÃ¼nmesi (Ã¶rneÄŸin \"train\", \"test\").\n","\n","- **`cache_dir`**:\n","  - Verinin Ã¶nbelleÄŸe alÄ±nacaÄŸÄ± dizin.\n","\n","- **`features`**:\n","  - Ã–zelliklerin aÃ§Ä±kÃ§a belirtildiÄŸi yer.\n","\n","- **`download_config`**:\n","  - Ä°ndirme yapÄ±landÄ±rma ayarlarÄ±.\n","\n","- **`download_mode`**:\n","  - Ä°ndirme modu: \"reuse_dataset_if_exists\", \"reuse_cache_if_exists\", \"force_redownload\".\n","\n","- **`verification_mode`**:\n","  - Veri setinin doÄŸrulama modu.\n","\n","- **`ignore_verifications`**:\n","  - ArtÄ±k kullanÄ±lmÄ±yor, doÄŸrulamalarÄ± atlamak iÃ§in.\n","\n","- **`keep_in_memory`**:\n","  - EÄŸer True ise, veri seti bellekte tutulur.\n","\n","- **`save_infos`**:\n","  - EÄŸer True ise, veri seti bilgileri kaydedilir.\n","\n","- **`revision`**:\n","  - YÃ¼klenecek veri setinin versiyonu veya commit ID'si.\n","\n","- **`token`**:\n","  - Private veri setleri iÃ§in kullanÄ±lÄ±r, bir token saÄŸlar.\n","\n","- **`use_auth_token`**:\n","  - ArtÄ±k kullanÄ±lmÄ±yor, oturum aÃ§ma token'Ä± iÃ§in.\n","\n","- **`task`**:\n","  - ArtÄ±k kullanÄ±lmÄ±yor, veri seti yÃ¼kleme gÃ¶revini belirtmek iÃ§in.\n","\n","- **`streaming`**:\n","  - EÄŸer True ise, veri seti akÄ±ÅŸ modunda yÃ¼klenir.\n","\n","- **`num_proc`**:\n","  - Ã‡ok iÅŸlemcili veri iÅŸleme iÃ§in iÅŸlemci sayÄ±sÄ±.\n","\n","- **`storage_options`**:\n","  - Depolama seÃ§enekleri.\n","\n","- **`trust_remote_code`**:\n","  - EÄŸer True ise, uzaktan kod Ã§alÄ±ÅŸtÄ±rmaya izin verir.\n","\n","- **`**config_kwargs`**:\n","  - DiÄŸer ek yapÄ±landÄ±rma argÃ¼manlarÄ±.\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T21:06:08.922137Z","iopub.status.busy":"2024-06-25T21:06:08.921718Z","iopub.status.idle":"2024-06-25T21:06:12.685624Z","shell.execute_reply":"2024-06-25T21:06:12.684489Z","shell.execute_reply.started":"2024-06-25T21:06:08.922104Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ea224c77d084e8686960d56868bfae5","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/497 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bed1e898ff03413ea6a00b805f31baf2","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/1.22M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bb45d394c62949a69c30c4c590bda0cf","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/119k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d26a4725617844efad218bd8b1268dd6","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/472 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3353d5dec84b45e78168846e271bcead","version_major":2,"version_minor":0},"text/plain":["Generating test split:   0%|          | 0/49 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dataset = load_dataset('Trelis/tiny-shakespeare', split='train')"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T21:06:12.687600Z","iopub.status.busy":"2024-06-25T21:06:12.687277Z","iopub.status.idle":"2024-06-25T21:06:12.695599Z","shell.execute_reply":"2024-06-25T21:06:12.694271Z","shell.execute_reply.started":"2024-06-25T21:06:12.687573Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset({\n","\n","    features: ['Text'],\n","\n","    num_rows: 472\n","\n","})\n","\n","======\n","\n","{'Text': \"First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you know Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us kill him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be done: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citizens, the patricians good.\\nWhat authority surfeits on would relieve us: if they\\nwould yield us but the superfluity, while it were\\nwholesome, we might guess they relieved us humanely;\\nbut they think we are too dear: the leanness that\\nafflicts us, the object of our misery, is as an\\ninventory to particularise their abundance; our\\nsufferance is a gain to them Let us revenge this with\\nour pikes, ere we become rakes: for the gods know I\\nspeak this in hunger for bread, not in thirst for revenge.\\n\\nSecond Citizen:\\nWould you proceed especially against Caius Marcius?\\n\\nAll:\\nAgainst him first: he's a very dog to the commonalty.\\n\\nSecond Citizen:\\nConsider you what services he has done for his country?\\n\\nFirst Citizen:\\nVery well; and could be content to give him good\\nreport fort, but that he pays himself with being proud.\\n\\nSecond Citizen:\\nNay, but speak not maliciously.\\n\\nFirst Citizen:\\nI say unto you, what he hath done famously, he did\\nit to that end: though soft-conscienced men can be\\ncontent to say it was for his country he did it to\\nplease his mother and to be partly proud; which he\\nis, even till the altitude of his virtue.\\n\\nSecond Citizen:\\nWhat he cannot help in his nature, you account a\\nvice in him. You must in no way say he is covetous.\\n\\nFirst Citizen:\\nIf I must not, I need not be barren of accusations;\\nhe hath faults, with surplus, to tire in repetition.\\nWhat shouts are these? The other side o' the city\\nis risen: why stay we prating here? to the Capitol!\\n\\nAll:\\nCome, come.\\n\\nFirst Citizen:\\nSoft! who comes here?\\n\\nSecond Citizen:\\nWorthy Menenius Agrippa; one that hath always loved\\nthe people.\\n\\nFirst Citizen:\\nHe's one honest enough: would all the rest were so!\\n\\nMENENIUS:\\nWhat work's, my countrymen, in hand? where go you\\nWith bats and clubs? The matter? speak, I pray you.\\n\\nFirst Citizen:\\nOur business is not unknown to the senate; they have\\nhad inkling this fortnight what we intend to do,\\nwhich now we'll show 'em in deeds. They say poor\\nsuitors have strong breaths: they shall know we\\nhave strong arms too.\\n\\nMENENIUS:\\nWhy, masters, my good friends, mine honest neighbours,\\nWill you undo yourselves?\\n\\nFirst Citizen:\\nWe cannot, sir, we are undone already.\\n\\nMENENIUS:\\nI tell you, friends, most charitable care\\nHave the patricians of you. For your wants,\\nYour suffering in this dearth, you may as well\\nStrike at the heaven with your staves as lift them\\nAgainst the Roman state, whose course will on\\nThe way it takes, cracking ten thousand curbs\\nOf more strong link asunder than can ever\\nAppear in your impediment. For the dearth,\\nThe gods, not the patricians, make it, and\\nYour knees to them, not arms, must help.\"}\n"]}],"source":["print(dataset)\n","print(\"======\")\n","print(dataset[0])"]},{"cell_type":"markdown","metadata":{},"source":["## ðŸ¤— Hugging Face Tokenizer KÃ¼tÃ¼phanesi\n","\n","### Parametreler\n","\n","- **`text`**:\n","  - Tokenize edilecek metin veya metinlerin listesi.\n","\n","- **`text_pair`**:\n","  - Ä°kinci bir metin veya metinlerin listesi, Ã§ift metinli modeller iÃ§in kullanÄ±lÄ±r.\n","\n","- **`text_target`**:\n","  - Hedef metin veya metinlerin listesi (genellikle seq2seq modelleri iÃ§in kullanÄ±lÄ±r).\n","\n","- **`text_pair_target`**:\n","  - Hedef ikinci metin veya metinlerin listesi, Ã§ift metinli modeller iÃ§in kullanÄ±lÄ±r.\n","\n","- **`add_special_tokens`**:\n","  - Ã–zel tokenler ekler (Ã¶rneÄŸin [CLS], [SEP]). True olmasÄ±, modeli daha iyi performans gÃ¶sterir.\n","\n","- **`padding`**:\n","  - Padding stratejisi: True, False, \"longest\", \"max_length\".\n","\n","- **`truncation`**:\n","  - Kesme stratejisi: True, False, \"longest_first\", \"only_first\".\n","\n","- **`max_length`**:\n","  - Maksimum token sayÄ±sÄ±. YÃ¼ksek deÄŸerler daha fazla bilgi taÅŸÄ±r ama daha fazla bellek kullanÄ±r.\n","\n","- **`stride`**:\n","  - Kesme sÄ±rasÄ±nda kayma boyutu. Uzun metinler iÃ§in daha kÃ¼Ã§Ã¼k deÄŸerler kullanÄ±ÅŸlÄ± olabilir.\n","\n","- **`is_split_into_words`**:\n","  - EÄŸer True ise, metin kelimelere bÃ¶lÃ¼nmÃ¼ÅŸ olarak kabul edilir.\n","\n","- **`pad_to_multiple_of`**:\n","  - Padding boyutunun bir katÄ± olacak ÅŸekilde padding ekler.\n","\n","- **`return_tensors`**:\n","  - DÃ¶ndÃ¼rÃ¼lecek tensÃ¶r tipi: 'pt', 'tf', 'np'.\n","\n","- **`return_token_type_ids`**:\n","  - EÄŸer True ise, token tipi ID'lerini dÃ¶ndÃ¼rÃ¼r.\n","\n","- **`return_attention_mask`**:\n","  - EÄŸer True ise, attention maskelerini dÃ¶ndÃ¼rÃ¼r.\n","\n","- **`return_overflowing_tokens`**:\n","  - EÄŸer True ise, taÅŸan tokenleri dÃ¶ndÃ¼rÃ¼r.\n","\n","- **`return_special_tokens_mask`**:\n","  - EÄŸer True ise, Ã¶zel token maskesini dÃ¶ndÃ¼rÃ¼r.\n","\n","- **`return_offsets_mapping`**:\n","  - EÄŸer True ise, offset mapping dÃ¶ndÃ¼rÃ¼r.\n","\n","- **`return_length`**:\n","  - EÄŸer True ise, token uzunluklarÄ±nÄ± dÃ¶ndÃ¼rÃ¼r.\n","\n","- **`verbose`**:\n","  - EÄŸer True ise, iÅŸlem hakkÄ±nda daha fazla bilgi verir.\n","\n","- **`**kwargs`**:\n","  - DiÄŸer ek argÃ¼manlar.\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T21:06:18.235272Z","iopub.status.busy":"2024-06-25T21:06:18.234420Z","iopub.status.idle":"2024-06-25T21:06:19.276633Z","shell.execute_reply":"2024-06-25T21:06:19.275595Z","shell.execute_reply.started":"2024-06-25T21:06:18.235230Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4835bef7c2ee4e43a9ec8951aea9c2f2","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["c:\\Users\\90530\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\90530\\.cache\\huggingface\\hub\\models--openai-community--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n","\n","To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n","\n","  warnings.warn(message)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ba912bd4208643f085fa20d622b9998b","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"06124c8297ee480d8f45149197e90a07","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e2759b10fd14fc19804c1d9f60ee5e3","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a19a62546a684d30b8de43d54b3f073d","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["base_model_name = \"openai-community/gpt2\"\n","\n","tokenizer = GPT2Tokenizer.from_pretrained(base_model_name)\n","\n","tokenizer.pad_token = tokenizer.eos_token"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T21:06:19.278484Z","iopub.status.busy":"2024-06-25T21:06:19.278170Z","iopub.status.idle":"2024-06-25T21:06:19.283815Z","shell.execute_reply":"2024-06-25T21:06:19.282836Z","shell.execute_reply.started":"2024-06-25T21:06:19.278452Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["GPT2Tokenizer(name_or_path='openai-community/gpt2', vocab_size=50257, model_max_length=1024, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n","\n","\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n","\n","}\n"]}],"source":["print(tokenizer)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T21:06:20.780656Z","iopub.status.busy":"2024-06-25T21:06:20.780207Z","iopub.status.idle":"2024-06-25T21:06:26.803565Z","shell.execute_reply":"2024-06-25T21:06:26.802712Z","shell.execute_reply.started":"2024-06-25T21:06:20.780621Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"889f2b8b7e9a4984a2da882bdb64862a","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/472 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["def text_tokenizer(text):\n","    tokenized_output = tokenizer(\n","        text['Text'], \n","        truncation=True,\n","        padding='max_length', \n","        max_length=128\n","    )\n","\n","    # labels input_ids ile aynÄ± olacak\n","    tokenized_output['labels'] = tokenized_output['input_ids'].copy()\n","    return tokenized_output\n","\n","train_data = dataset.map(text_tokenizer, batched=True)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T21:06:26.805739Z","iopub.status.busy":"2024-06-25T21:06:26.805379Z","iopub.status.idle":"2024-06-25T21:06:26.812915Z","shell.execute_reply":"2024-06-25T21:06:26.811921Z","shell.execute_reply.started":"2024-06-25T21:06:26.805705Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset({\n","\n","    features: ['Text', 'input_ids', 'attention_mask', 'labels'],\n","\n","    num_rows: 472\n","\n","})\n","\n","=====\n","\n","{'Text': \"First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you know Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us kill him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be done: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citizens, the patricians good.\\nWhat authority surfeits on would relieve us: if they\\nwould yield us but the superfluity, while it were\\nwholesome, we might guess they relieved us humanely;\\nbut they think we are too dear: the leanness that\\nafflicts us, the object of our misery, is as an\\ninventory to particularise their abundance; our\\nsufferance is a gain to them Let us revenge this with\\nour pikes, ere we become rakes: for the gods know I\\nspeak this in hunger for bread, not in thirst for revenge.\\n\\nSecond Citizen:\\nWould you proceed especially against Caius Marcius?\\n\\nAll:\\nAgainst him first: he's a very dog to the commonalty.\\n\\nSecond Citizen:\\nConsider you what services he has done for his country?\\n\\nFirst Citizen:\\nVery well; and could be content to give him good\\nreport fort, but that he pays himself with being proud.\\n\\nSecond Citizen:\\nNay, but speak not maliciously.\\n\\nFirst Citizen:\\nI say unto you, what he hath done famously, he did\\nit to that end: though soft-conscienced men can be\\ncontent to say it was for his country he did it to\\nplease his mother and to be partly proud; which he\\nis, even till the altitude of his virtue.\\n\\nSecond Citizen:\\nWhat he cannot help in his nature, you account a\\nvice in him. You must in no way say he is covetous.\\n\\nFirst Citizen:\\nIf I must not, I need not be barren of accusations;\\nhe hath faults, with surplus, to tire in repetition.\\nWhat shouts are these? The other side o' the city\\nis risen: why stay we prating here? to the Capitol!\\n\\nAll:\\nCome, come.\\n\\nFirst Citizen:\\nSoft! who comes here?\\n\\nSecond Citizen:\\nWorthy Menenius Agrippa; one that hath always loved\\nthe people.\\n\\nFirst Citizen:\\nHe's one honest enough: would all the rest were so!\\n\\nMENENIUS:\\nWhat work's, my countrymen, in hand? where go you\\nWith bats and clubs? The matter? speak, I pray you.\\n\\nFirst Citizen:\\nOur business is not unknown to the senate; they have\\nhad inkling this fortnight what we intend to do,\\nwhich now we'll show 'em in deeds. They say poor\\nsuitors have strong breaths: they shall know we\\nhave strong arms too.\\n\\nMENENIUS:\\nWhy, masters, my good friends, mine honest neighbours,\\nWill you undo yourselves?\\n\\nFirst Citizen:\\nWe cannot, sir, we are undone already.\\n\\nMENENIUS:\\nI tell you, friends, most charitable care\\nHave the patricians of you. For your wants,\\nYour suffering in this dearth, you may as well\\nStrike at the heaven with your staves as lift them\\nAgainst the Roman state, whose course will on\\nThe way it takes, cracking ten thousand curbs\\nOf more strong link asunder than can ever\\nAppear in your impediment. For the dearth,\\nThe gods, not the patricians, make it, and\\nYour knees to them, not arms, must help.\", 'input_ids': [5962, 22307, 25, 198, 8421, 356, 5120, 597, 2252, 11, 3285, 502, 2740, 13, 198, 198, 3237, 25, 198, 5248, 461, 11, 2740, 13, 198, 198, 5962, 22307, 25, 198, 1639, 389, 477, 12939, 2138, 284, 4656, 621, 284, 1145, 680, 30, 198, 198, 3237, 25, 198, 4965, 5634, 13, 12939, 13, 198, 198, 5962, 22307, 25, 198, 5962, 11, 345, 760, 327, 1872, 385, 1526, 28599, 318, 4039, 4472, 284, 262, 661, 13, 198, 198, 3237, 25, 198, 1135, 760, 470, 11, 356, 760, 470, 13, 198, 198, 5962, 22307, 25, 198, 5756, 514, 1494, 683, 11, 290, 356, 1183, 423, 11676, 379, 674, 898, 2756, 13, 198, 3792, 470, 257, 15593, 30, 198, 198, 3237, 25, 198, 2949, 517, 3375, 319, 470, 26, 1309, 340, 307], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [5962, 22307, 25, 198, 8421, 356, 5120, 597, 2252, 11, 3285, 502, 2740, 13, 198, 198, 3237, 25, 198, 5248, 461, 11, 2740, 13, 198, 198, 5962, 22307, 25, 198, 1639, 389, 477, 12939, 2138, 284, 4656, 621, 284, 1145, 680, 30, 198, 198, 3237, 25, 198, 4965, 5634, 13, 12939, 13, 198, 198, 5962, 22307, 25, 198, 5962, 11, 345, 760, 327, 1872, 385, 1526, 28599, 318, 4039, 4472, 284, 262, 661, 13, 198, 198, 3237, 25, 198, 1135, 760, 470, 11, 356, 760, 470, 13, 198, 198, 5962, 22307, 25, 198, 5756, 514, 1494, 683, 11, 290, 356, 1183, 423, 11676, 379, 674, 898, 2756, 13, 198, 3792, 470, 257, 15593, 30, 198, 198, 3237, 25, 198, 2949, 517, 3375, 319, 470, 26, 1309, 340, 307]}\n"]}],"source":["print(train_data)\n","print(\"=====\")\n","print(train_data[0])"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T21:06:26.814342Z","iopub.status.busy":"2024-06-25T21:06:26.814050Z","iopub.status.idle":"2024-06-25T21:06:30.634624Z","shell.execute_reply":"2024-06-25T21:06:30.633669Z","shell.execute_reply.started":"2024-06-25T21:06:26.814319Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c153a5a8e364433795797010e5a1f5b2","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e229a581f704ce1ab12b83e8b5dc70a","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(50257, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0-11): 12 x GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",")"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["model = GPT2LMHeadModel.from_pretrained(base_model_name)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # GPU varsa GPU kullanÄ±r, yoksa CPU kullanÄ±r\n","\n","model.to(device) "]},{"cell_type":"markdown","metadata":{},"source":["## ðŸ¤— Hugging Face TrainingArguments KÃ¼tÃ¼phanesi\n","\n","### Parametreler\n","\n","- **`output_dir`**:\n","  - EÄŸitim sÄ±rasÄ±nda ve sonrasÄ±nda sonuÃ§larÄ±n kaydedileceÄŸi dizin.\n","\n","- **`overwrite_output_dir`**:\n","  - EÄŸer True ise, mevcut `output_dir` iÃ§eriÄŸini Ã¼zerine yazar.\n","\n","- **`do_train`**:\n","  - EÄŸitim iÅŸleminin yapÄ±lÄ±p yapÄ±lmayacaÄŸÄ±nÄ± belirtir.\n","\n","- **`do_eval`**:\n","  - DeÄŸerlendirme iÅŸleminin yapÄ±lÄ±p yapÄ±lmayacaÄŸÄ±nÄ± belirtir.\n","\n","- **`do_predict`**:\n","  - Tahmin iÅŸleminin yapÄ±lÄ±p yapÄ±lmayacaÄŸÄ±nÄ± belirtir.\n","\n","- **`eval_strategy`**:\n","  - DeÄŸerlendirme stratejisi: 'no', 'steps' veya 'epoch'.\n","\n","- **`prediction_loss_only`**:\n","  - EÄŸer True ise, sadece kayÄ±p hesaplanÄ±r, tahminler dÃ¶ndÃ¼rÃ¼lmez.\n","\n","- **`per_device_train_batch_size`**:\n","  - Her bir cihaz (GPU/CPU) iÃ§in eÄŸitim batch boyutu.\n","\n","- **`per_device_eval_batch_size`**:\n","  - Her bir cihaz (GPU/CPU) iÃ§in deÄŸerlendirme batch boyutu.\n","\n","- **`gradient_accumulation_steps`**:\n","  - Gradient biriktirme adÄ±mlarÄ±. YÃ¼ksek deÄŸerler bellek kullanÄ±mÄ±nÄ± azaltÄ±r ama eÄŸitim sÃ¼resini uzatÄ±r.\n","\n","- **`eval_accumulation_steps`**:\n","  - DeÄŸerlendirme biriktirme adÄ±mlarÄ±. YÃ¼ksek deÄŸerler bellek kullanÄ±mÄ±nÄ± azaltÄ±r ama deÄŸerlendirme sÃ¼resini uzatÄ±r.\n","\n","- **`eval_delay`**:\n","  - EÄŸitim baÅŸladÄ±ktan sonra ilk deÄŸerlendirmenin yapÄ±lacaÄŸÄ± adÄ±m sayÄ±sÄ±.\n","\n","- **`learning_rate`**:\n","  - Ã–ÄŸrenme oranÄ±. YÃ¼ksek deÄŸerler daha hÄ±zlÄ± Ã¶ÄŸrenir ama aÅŸÄ±rÄ± Ã¶ÄŸrenmeye (overfitting) yol aÃ§abilir.\n","\n","- **`weight_decay`**:\n","  - AÄŸÄ±rlÄ±klarÄ±n kÃ¼Ã§Ã¼lme oranÄ±. YÃ¼ksek deÄŸerler modelin genelleme yeteneÄŸini artÄ±rabilir ama Ã¶ÄŸrenme yavaÅŸlar.\n","\n","- **`adam_beta1`**:\n","  - Adam optimizasyon algoritmasÄ± iÃ§in beta1 parametresi.\n","\n","- **`adam_beta2`**:\n","  - Adam optimizasyon algoritmasÄ± iÃ§in beta2 parametresi.\n","\n","- **`adam_epsilon`**:\n","  - Adam optimizasyon algoritmasÄ± iÃ§in epsilon parametresi.\n","\n","- **`max_grad_norm`**:\n","  - Gradientlerin maksimum normu. BÃ¼yÃ¼k deÄŸerler modelin stabilitesini artÄ±rabilir.\n","\n","- **`num_train_epochs`**:\n","  - EÄŸitim iÃ§in epoch sayÄ±sÄ±. YÃ¼ksek deÄŸerler daha fazla Ã¶ÄŸrenme saÄŸlar ama aÅŸÄ±rÄ± Ã¶ÄŸrenmeye yol aÃ§abilir.\n","\n","- **`max_steps`**:\n","  - Maksimum eÄŸitim adÄ±m sayÄ±sÄ±. -1 ise, tÃ¼m epoch'lar tamamlanÄ±r.\n","\n","- **`lr_scheduler_type`**:\n","  - Ã–ÄŸrenme oranÄ± zamanlayÄ±cÄ± tipi.\n","\n","- **`lr_scheduler_kwargs`**:\n","  - Ã–ÄŸrenme oranÄ± zamanlayÄ±cÄ±sÄ± iÃ§in ek parametreler.\n","\n","- **`warmup_ratio`**:\n","  - Ã–ÄŸrenme oranÄ± Ä±sÄ±nma oranÄ±. YÃ¼ksek deÄŸerler baÅŸlangÄ±Ã§ta daha yavaÅŸ Ã¶ÄŸrenme saÄŸlar.\n","\n","- **`warmup_steps`**:\n","  - Ã–ÄŸrenme oranÄ± Ä±sÄ±nma adÄ±m sayÄ±sÄ±. YÃ¼ksek deÄŸerler baÅŸlangÄ±Ã§ta daha yavaÅŸ Ã¶ÄŸrenme saÄŸlar.\n","\n","- **`log_level`**:\n","  - Log seviyesi. 'passive', 'info', 'warning', 'error' veya 'critical'.\n","\n","- **`log_level_replica`**:\n","  - Ã‡oklu GPU eÄŸitiminde log seviyesi.\n","\n","- **`log_on_each_node`**:\n","  - Ã‡oklu node eÄŸitiminde her node iÃ§in loglama yapÄ±lÄ±r.\n","\n","- **`logging_dir`**:\n","  - TensorBoard loglarÄ± iÃ§in dizin.\n","\n","- **`logging_strategy`**:\n","  - Loglama stratejisi: 'no', 'steps' veya 'epoch'.\n","\n","- **`logging_first_step`**:\n","  - EÄŸer True ise, ilk adÄ±mda loglama yapÄ±lÄ±r.\n","\n","- **`logging_steps`**:\n","  - KaÃ§ adÄ±mda bir loglama yapÄ±lacaÄŸÄ±.\n","\n","- **`logging_nan_inf_filter`**:\n","  - EÄŸer True ise, NaN ve sonsuz deÄŸerler loglanmaz.\n","\n","- **`save_strategy`**:\n","  - Modelin kaydedilme stratejisi: 'no', 'steps' veya 'epoch'.\n","\n","- **`save_steps`**:\n","  - KaÃ§ adÄ±mda bir modelin kaydedileceÄŸi.\n","\n","- **`save_total_limit`**:\n","  - Maksimum kaÃ§ model kaydedileceÄŸi.\n","\n","- **`save_safetensors`**:\n","  - Modelin gÃ¼venli tensÃ¶r formatÄ±nda kaydedilip kaydedilmeyeceÄŸi.\n","\n","- **`save_on_each_node`**:\n","  - EÄŸer True ise, her node'da model kaydedilir.\n","\n","- **`save_only_model`**:\n","  - EÄŸer True ise, sadece model kaydedilir, optimizer ve lr scheduler kaydedilmez.\n","\n","- **`restore_callback_states_from_checkpoint`**:\n","  - Callback durumlarÄ±nÄ±n checkpoint'ten geri yÃ¼klenip yÃ¼klenmeyeceÄŸi.\n","\n","- **`no_cuda`**:\n","  - EÄŸer True ise, GPU kullanÄ±lmaz.\n","\n","- **`use_cpu`**:\n","  - EÄŸer True ise, CPU kullanÄ±lÄ±r.\n","\n","- **`use_mps_device`**:\n","  - EÄŸer True ise, MacOS Metal Performance Shaders kullanÄ±lÄ±r.\n","\n","- **`seed`**:\n","  - Rastgelelik iÃ§in seed deÄŸeri.\n","\n","- **`data_seed`**:\n","  - Veri yÃ¼kleme iÃ§in seed deÄŸeri.\n","\n","- **`jit_mode_eval`**:\n","  - EÄŸer True ise, PyTorch JIT modu kullanÄ±lÄ±r.\n","\n","- **`use_ipex`**:\n","  - EÄŸer True ise, Intel Extension for PyTorch kullanÄ±lÄ±r.\n","\n","- **`bf16`**:\n","  - EÄŸer True ise, bfloat16 kullanÄ±lÄ±r.\n","\n","- **`fp16`**:\n","  - EÄŸer True ise, float16 kullanÄ±lÄ±r.\n","\n","- **`fp16_opt_level`**:\n","  - float16 optimizasyon seviyesi.\n","\n","- **`half_precision_backend`**:\n","  - YarÄ± hassasiyet arka ucu: 'auto', 'amp' veya 'apex'.\n","\n","- **`bf16_full_eval`**:\n","  - EÄŸer True ise, bfloat16 tam deÄŸerlendirme yapÄ±lÄ±r.\n","\n","- **`fp16_full_eval`**:\n","  - EÄŸer True ise, float16 tam deÄŸerlendirme yapÄ±lÄ±r.\n","\n","- **`tf32`**:\n","  - EÄŸer True ise, TensorFloat-32 kullanÄ±lÄ±r.\n","\n","- **`local_rank`**:\n","  - Ã‡oklu GPU eÄŸitiminde lokal rank.\n","\n","- **`ddp_backend`**:\n","  - DDP backend tipi: 'nccl', 'gloo', 'mpi'.\n","\n","- **`tpu_num_cores`**:\n","  - TPU Ã§ekirdek sayÄ±sÄ±.\n","\n","- **`tpu_metrics_debug`**:\n","  - TPU metriklerinin debug bilgilerini iÃ§erir.\n","\n","- **`debug`**:\n","  - Debug seÃ§eneÄŸi: 'underflow_overflow', 'poor_optimization'.\n","\n","- **`dataloader_drop_last`**:\n","  - EÄŸer True ise, dataloader son batch'i dÃ¼ÅŸÃ¼rÃ¼r.\n","\n","- **`eval_steps`**:\n","  - DeÄŸerlendirme adÄ±m sayÄ±sÄ±.\n","\n","- **`dataloader_num_workers`**:\n","  - Dataloader iÃ§in Ã§alÄ±ÅŸan sayÄ±sÄ±. YÃ¼ksek deÄŸerler hÄ±z artÄ±rÄ±r ama daha fazla bellek kullanÄ±r.\n","\n","- **`dataloader_prefetch_factor`**:\n","  - Dataloader iÃ§in prefetch faktÃ¶rÃ¼. YÃ¼ksek deÄŸerler hÄ±z artÄ±rÄ±r ama daha fazla bellek kullanÄ±r.\n","\n","- **`past_index`**:\n","  - GeÃ§miÅŸ index.\n","\n","- **`run_name`**:\n","  - Ã‡alÄ±ÅŸma ismi.\n","\n","- **`disable_tqdm`**:\n","  - EÄŸer True ise, tqdm progress bar devre dÄ±ÅŸÄ± bÄ±rakÄ±lÄ±r.\n","\n","- **`remove_unused_columns`**:\n","  - EÄŸer True ise, kullanÄ±lmayan sÃ¼tunlar veri setinden kaldÄ±rÄ±lÄ±r.\n","\n","- **`label_names`**:\n","  - Label isimleri.\n","\n","- **`load_best_model_at_end`**:\n","  - EÄŸitim sonunda en iyi modelin yÃ¼klenip yÃ¼klenmeyeceÄŸi.\n","\n","- **`metric_for_best_model`**:\n","  - En iyi modelin seÃ§ilmesi iÃ§in kullanÄ±lacak metrik.\n","\n","- **`greater_is_better`**:\n","  - EÄŸer True ise, metriklerde yÃ¼ksek deÄŸerler daha iyi olarak kabul edilir.\n","\n","- **`ignore_data_skip`**:\n","  - EÄŸer True ise, veri atlamalarÄ± gÃ¶z ardÄ± edilir.\n","\n","- **`fsdp`**:\n","  - Fully Sharded Data Parallel ayarlarÄ±.\n","\n","- **`fsdp_min_num_params`**:\n","  - Fully Sharded Data Parallel iÃ§in minimum parametre sayÄ±sÄ±.\n","\n","- **`fsdp_config`**:\n","  - Fully Sharded Data Parallel iÃ§in ek ayarlar.\n","\n","- **`fsdp_transformer_layer_cls_to_wrap`**:\n","  - Fully Sharded Data Parallel iÃ§in transformer layer sÄ±nÄ±fÄ±.\n","\n","- **`accelerator_config`**:\n","  - Accelerator iÃ§in ek ayarlar.\n","\n","- **`deepspeed`**:\n","  - DeepSpeed yapÄ±landÄ±rmasÄ±.\n","\n","- **`label_smoothing_factor`**:\n","  - Label smoothing faktÃ¶rÃ¼.\n","\n","- **`optim`**:\n","  - Optimizasyon algoritmasÄ±.\n","\n","- **`optim_args`**:\n","  - Optimizasyon algoritmasÄ± iÃ§in ek argÃ¼manlar.\n","\n","- **`adafactor`**:\n","  - EÄŸer True ise, Adafactor optimizasyon algoritmasÄ± kullanÄ±lÄ±r.\n","\n","- **`group_by_length`**:\n","  - EÄŸer True ise, input uzunluÄŸuna gÃ¶re gruplanÄ±r.\n","\n","- **`length_column_name`**:\n","  - Uzunluk sÃ¼tunu ismi.\n","\n","- **`report_to`**:\n","  - Raporlama platformlarÄ± (Ã¶rneÄŸin 'wandb').\n","\n","- **`ddp_find_unused_parameters`**:\n","  - DDP'de kullanÄ±lmayan parametrelerin bulunmasÄ±.\n","\n","- **`ddp_bucket_cap_mb`**:\n","  - DDP bucket kapasitesi.\n","\n","- **`ddp_broadcast_buffers`**:\n","  - DDP broadcast buffer'larÄ±.\n","\n","- **`dataloader_pin_memory`**:\n","  - Dataloader iÃ§in bellek pinleme.\n","\n","- **`dataloader_persistent_workers`**:\n","  - Dataloader iÃ§in kalÄ±cÄ± Ã§alÄ±ÅŸanlar.\n","\n","- **`skip_memory_metrics`**:\n","  - EÄŸer True ise, bellek metrikleri atlanÄ±r.\n","\n","- **`use_legacy_prediction_loop`**:\n","  - EÄŸer True ise, eski tahmin dÃ¶ngÃ¼sÃ¼ kullanÄ±lÄ±r.\n","\n","- **`push_to_hub`**:\n","  - EÄŸer True ise, model Hugging Face Hub'a itilir.\n","\n","- **`resume_from_checkpoint`**:\n","  - Checkpoint'ten devam edilir.\n","\n","- **`hub_model_id`**:\n","  - Hugging Face Hub model ID.\n","\n","- **`hub_strategy`**:\n","  - Hub stratejisi.\n","\n","- **`hub_token`**:\n","  - Hugging Face Hub token.\n","\n","- **`hub_private_repo`**:\n","  - EÄŸer True ise, Ã¶zel repo kullanÄ±lÄ±r.\n","\n","- **`hub_always_push`**:\n","  - EÄŸer True ise, her zaman Hub'a itilir.\n","\n","- **`gradient_checkpointing`**:\n","  - EÄŸer True ise, gradient checkpointing yapÄ±lÄ±r.\n","\n","- **`gradient_checkpointing_kwargs`**:\n","  - Gradient checkpointing iÃ§in ek argÃ¼manlar.\n","\n","- **`include_inputs_for_metrics`**:\n","  - EÄŸer True ise, deÄŸerlendirme metrikleri iÃ§in inputlar da dahil edilir.\n","\n","- **`eval_do_concat_batches`**:\n","  - EÄŸer True ise, deÄŸerlendirme batch'leri birleÅŸtirilir.\n","\n","- **`fp16_backend`**:\n","  - float16 arka ucu.\n","\n","- **`evaluation_strategy`**:\n","  - DeÄŸerlendirme stratejisi: 'no', 'steps' veya 'epoch'.\n","\n","- **`push_to_hub_model_id`**:\n","  - Hub model ID.\n","\n","- **`push_to_hub_organization`**:\n","  - Hub organizasyon ID.\n","\n","- **`push_to_hub_token`**:\n","  - Hub token.\n","\n","- **`mp_parameters`**:\n","  - Model paralel parametreler.\n","\n","- **`auto_find_batch_size`**:\n","  - EÄŸer True ise, batch boyutu otomatik bulunur.\n","\n","- **`full_determinism`**:\n","  - EÄŸer True ise, deterministik eÄŸitim yapÄ±lÄ±r.\n","\n","- **`torchdynamo`**:\n","  - TorchDynamo kullanÄ±mÄ±.\n","\n","- **`ray_scope`**:\n","  - Ray scope.\n","\n","- **`ddp_timeout`**:\n","  - DDP timeout sÃ¼resi.\n","\n","- **`torch_compile`**:\n","  - EÄŸer True ise, Torch compile kullanÄ±lÄ±r.\n","\n","- **`torch_compile_backend`**:\n","  - Torch compile backend.\n","\n","- **`torch_compile_mode`**:\n","  - Torch compile modu.\n","\n","- **`dispatch_batches`**:\n","  - Batch dispatching.\n","\n","- **`split_batches`**:\n","  - Batch splitting.\n","\n","- **`include_tokens_per_second`**:\n","  - EÄŸer True ise, saniye baÅŸÄ±na token sayÄ±sÄ± dahil edilir.\n","\n","- **`include_num_input_tokens_seen`**:\n","  - EÄŸer True ise, gÃ¶rÃ¼len input token sayÄ±sÄ± dahil edilir.\n","\n","- **`neftune_noise_alpha`**:\n","  - Neptune noise alpha.\n","\n","- **`optim_target_modules`**:\n","  - Optimizasyon hedef modÃ¼ller.\n","\n","- **`batch_eval_metrics`**:\n","  - EÄŸer True ise, batch deÄŸerlendirme metrikleri hesaplanÄ±r."]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T21:15:04.856982Z","iopub.status.busy":"2024-06-25T21:15:04.856252Z","iopub.status.idle":"2024-06-25T21:15:04.897182Z","shell.execute_reply":"2024-06-25T21:15:04.896040Z","shell.execute_reply.started":"2024-06-25T21:15:04.856935Z"},"trusted":true},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir='./results',\n","    evaluation_strategy=\"no\", # Validasyon verisi olmadÄ±ÄŸÄ± iÃ§in bu seÃ§eneÄŸi kullanÄ±yoruz\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=1,  \n","    do_eval=False, # Validasyon verisi olmadÄ±ÄŸÄ± iÃ§in bu seÃ§eneÄŸi kullanÄ±yoruz\n","    num_train_epochs=10,\n","    weight_decay=0.01,\n","    push_to_hub=True, # Modeli huggingface hub'a yÃ¼klemek istediÄŸimizi belirtiyoruz, False olarak ayarlanÄ±rsa model yÃ¼klenmez\n","    hub_model_id='gpt2-shakespeare-text-generation' # push_to_hub=True olduÄŸunda modelin hub'da hangi isimle kaydedileceÄŸini belirtir\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## ðŸ¤— Hugging Face Trainer KÃ¼tÃ¼phanesi\n","\n","### Parametreler\n","\n","- **`model`**:\n","  - EÄŸitim ve deÄŸerlendirme iÃ§in kullanÄ±lacak model.\n","\n","- **`args`**:\n","  - EÄŸitim argÃ¼manlarÄ±, `TrainingArguments` sÄ±nÄ±fÄ± ile oluÅŸturulur.\n","\n","- **`data_collator`**:\n","  - Veriyi toplamak iÃ§in kullanÄ±lan data collator.\n","\n","- **`train_dataset`**:\n","  - EÄŸitim iÃ§in kullanÄ±lacak veri seti.\n","\n","- **`eval_dataset`**:\n","  - DeÄŸerlendirme iÃ§in kullanÄ±lacak veri seti.\n","\n","- **`tokenizer`**:\n","  - Metin verilerini modelin anlayabileceÄŸi sayÄ±sal deÄŸerlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.\n","\n","- **`model_init`**:\n","  - Modelin baÅŸlatÄ±lmasÄ± iÃ§in kullanÄ±lacak fonksiyon.\n","\n","- **`compute_metrics`**:\n","  - DeÄŸerlendirme metriklerini hesaplamak iÃ§in kullanÄ±lacak fonksiyon.\n","\n","- **`callbacks`**:\n","  - EÄŸitim sÃ¼recini izlemek ve kontrol etmek iÃ§in kullanÄ±lacak callback listesi.\n","\n","- **`optimizers`**:\n","  - Optimizasyon algoritmasÄ± ve Ã¶ÄŸrenme oranÄ± zamanlayÄ±cÄ±sÄ±.\n","\n","- **`preprocess_logits_for_metrics`**:\n","  - Metrik hesaplama iÃ§in logits'i Ã¶n iÅŸleme fonksiyonu.\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T21:15:06.292220Z","iopub.status.busy":"2024-06-25T21:15:06.291841Z","iopub.status.idle":"2024-06-25T21:15:06.626340Z","shell.execute_reply":"2024-06-25T21:15:06.625020Z","shell.execute_reply.started":"2024-06-25T21:15:06.292190Z"},"trusted":true},"outputs":[],"source":["trainer = Trainer(\n","    model=model, # Modelimiz\n","    args=training_args, # Training argÃ¼manlarÄ±mÄ±z\n","    train_dataset=train_data, # EÄŸitim verisetimiz\n",")"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T21:15:07.408742Z","iopub.status.busy":"2024-06-25T21:15:07.407826Z","iopub.status.idle":"2024-06-25T21:24:11.450712Z","shell.execute_reply":"2024-06-25T21:24:11.449517Z","shell.execute_reply.started":"2024-06-25T21:15:07.408693Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2360' max='2360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2360/2360 09:03, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.668800</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.437100</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>2.292200</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>2.218700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=2360, training_loss=2.370756168688758, metrics={'train_runtime': 543.5846, 'train_samples_per_second': 8.683, 'train_steps_per_second': 4.342, 'total_flos': 308324597760000.0, 'train_loss': 2.370756168688758, 'epoch': 10.0})"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# Wandb-key ile wandb hesabÄ±nÄ±za baÄŸlanabilirsiniz\n","trainer.train()"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T21:24:11.452821Z","iopub.status.busy":"2024-06-25T21:24:11.452532Z","iopub.status.idle":"2024-06-25T21:24:27.183914Z","shell.execute_reply":"2024-06-25T21:24:27.182663Z","shell.execute_reply.started":"2024-06-25T21:24:11.452796Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ee8121ae089a4f7caca0f77affb6d5ef","version_major":2,"version_minor":0},"text/plain":["Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9a40edb0c94b415eb866b587734457dc","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"11910254aaeb456ca10d7b27d6364e32","version_major":2,"version_minor":0},"text/plain":["events.out.tfevents.1719350107.805e69c35453.34.1:   0%|          | 0.00/6.30k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/fawern/gpt2-shakespeare-text-generation/commit/e8d2097247aa2219d71356996c82fe1a79164443', commit_message='End of training', commit_description='', oid='e8d2097247aa2219d71356996c82fe1a79164443', pr_url=None, pr_revision=None, pr_num=None)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["trainer.push_to_hub() # Modeli huggingface hub'a yÃ¼kler, push_to_hub=True olmalÄ±dÄ±r"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-06-25T13:04:41.973204Z","iopub.status.busy":"2024-06-25T13:04:41.972485Z","iopub.status.idle":"2024-06-25T13:04:41.993255Z","shell.execute_reply":"2024-06-25T13:04:41.991938Z","shell.execute_reply.started":"2024-06-25T13:04:41.973170Z"}},"source":["## ðŸ¤— Hugging Face `model.generate` KÃ¼tÃ¼phanesi\n","\n","### Parametreler\n","\n","- **`inputs`**:\n","  - Girdi tensÃ¶rÃ¼. Modelin kullanacaÄŸÄ± baÅŸlangÄ±Ã§ verileri.\n","\n","- **`generation_config`**:\n","  - Opsiyonel jenerasyon konfigÃ¼rasyonu. Jenerasyon sÃ¼reci iÃ§in yapÄ±landÄ±rma ayarlarÄ±.\n","\n","- **`logits_processor`**:\n","  - Opsiyonel logits iÅŸlemcisi listesi. Logits deÄŸerlerini iÅŸlemek ve dÃ¼zenlemek iÃ§in kullanÄ±lÄ±r.\n","\n","- **`stopping_criteria`**:\n","  - Opsiyonel durdurma kriterleri listesi. Jenerasyonun durmasÄ± gereken durumlarÄ± tanÄ±mlar.\n","\n","- **`prefix_allowed_tokens_fn`**:\n","  - Opsiyonel bir fonksiyon. Jenerasyon sÄ±rasÄ±nda izin verilen token'larÄ± belirtir.\n","\n","- **`synced_gpus`**:\n","  - EÄŸer True ise, Ã§oklu GPU senkronizasyonu yapÄ±lÄ±r.\n","\n","- **`assistant_model`**:\n","  - Opsiyonel yardÄ±mcÄ± model. Jenerasyon sÃ¼recinde destekleyici model olarak kullanÄ±lÄ±r.\n","\n","- **`streamer`**:\n","  - Opsiyonel bir streamer. Jenerasyon sonuÃ§larÄ±nÄ± anlÄ±k olarak aktarmak iÃ§in kullanÄ±lÄ±r.\n","\n","- **`negative_prompt_ids`**:\n","  - Opsiyonel negatif prompt ID'leri. Negatif Ã¶rneklerin ID'lerini iÃ§erir.\n","\n","- **`negative_prompt_attention_mask`**:\n","  - Opsiyonel negatif prompt dikkat maskesi. Negatif Ã¶rneklerin dikkat maskesini tanÄ±mlar."]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T21:37:05.969374Z","iopub.status.busy":"2024-06-25T21:37:05.968974Z","iopub.status.idle":"2024-06-25T21:37:05.977649Z","shell.execute_reply":"2024-06-25T21:37:05.976637Z","shell.execute_reply.started":"2024-06-25T21:37:05.969347Z"},"trusted":true},"outputs":[],"source":["input_texts = [\n","    \"To be, or not to be, that is the question:\",\n","    \"Two households, both alike in dignity, in fair Verona, where we lay our scene, from ancient grudge break to new mutiny\",\n","    \"All the world's a stage, and all the men and women merely players:\"\n","]\n","\n","trained_model = trainer.model\n","\n","def generator(text):\n","    # Text dizisini modelin anlayabileceÄŸi forma Ã§eviriyoruz\n","    input_ids = tokenizer.encode(text, return_tensors='pt').to(device)\n","    \n","    # Modeli kullanarak text Ã¼retimi yapÄ±yoruz\n","    output = trained_model.generate(\n","        input_ids,\n","        max_length=100,   \n","    )\n","    \n","    # Ãœretilen texti decode ediyoruz\n","    generated_text = tokenizer.decode(\n","        output[0], \n","        skip_special_tokens=True,\n","        num_return_sequences=1,\n","        no_repeat_ngram_size=2\n","    )\n","    \n","    return generated_text"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T21:37:08.429044Z","iopub.status.busy":"2024-06-25T21:37:08.428667Z","iopub.status.idle":"2024-06-25T21:37:09.734801Z","shell.execute_reply":"2024-06-25T21:37:09.733533Z","shell.execute_reply.started":"2024-06-25T21:37:08.429017Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["To be, or not to be, that is the question:\n","\n","\n","\n","First, I think, to be a matter of opinion.\n","\n","\n","\n","Second, I think it best to be a man;\n","\n","and therefore, as a man, as a man.\n","\n","\n","\n","Third, I think it best to be a farmer;\n","\n","and therefore, as a man.\n","\n","\n","\n","I think it best to be a soldier;\n","\n","and therefore, as a man.\n","\n","\n","\n","I think it best to be\n"]}],"source":["print(generator(input_texts[0]))"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T21:37:09.736897Z","iopub.status.busy":"2024-06-25T21:37:09.736609Z","iopub.status.idle":"2024-06-25T21:37:10.636311Z","shell.execute_reply":"2024-06-25T21:37:10.634274Z","shell.execute_reply.started":"2024-06-25T21:37:09.736873Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["Two households, both alike in dignity, in fair Verona, where we lay our scene, from ancient grudge break to new mutiny\n","\n","and to the clamour of the new-married's blood,\n","\n","The old and the new-married, the two kindreds,\n","\n","The old and the new-married, the old and the old,\n","\n","The two kindreds, the old and New-married,\n","\n","The old and the old, the old and the old,\n","\n","The old\n"]}],"source":["print(generator(input_texts[1]))"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T21:37:10.638266Z","iopub.status.busy":"2024-06-25T21:37:10.637869Z","iopub.status.idle":"2024-06-25T21:37:11.671865Z","shell.execute_reply":"2024-06-25T21:37:11.670832Z","shell.execute_reply.started":"2024-06-25T21:37:10.638228Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["All the world's a stage, and all the men and women merely players:\n","\n","The best is to play the best,\n","\n","And that's the best is to play the best.\n","\n","\n","\n","GLOUCESTER:\n","\n","\n","\n","PERDITA:\n","\n","I' the best is to play the best,\n","\n","And that's the best is to play the best.\n","\n","\n","\n","GLOUCESTER:\n","\n","\n","\n","PERDITA:\n","\n","I' the best is to play the best,\n","\n","\n"]}],"source":["print(generator(input_texts[2]))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":4}
