{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# warnings kütüphanesi uyarıları kapatmak için kullanılır\nimport warnings \nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GPU ve CUDA sürümlerini kontrol etmek için kullanılır\n!nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q -U transformers torch==2.2.1 datasets \n!echo \"Installations completed!\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom datasets import load_dataset, Dataset\nfrom sklearn.model_selection import train_test_split\n\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom transformers import TrainingArguments, Trainer\n\nfrom sklearn.metrics import (accuracy_score, \n                             precision_score, \n                             recall_score, \n                             f1_score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 🤗 Hugging Face Datasets Kütüphanesi\n\n### Parametreler\n\n- **`path`**:\n  - Yüklenecek veri setinin yolu veya ismi. Örnek: \"imdb\", \"glue\".\n\n- **`name`**:\n  - Yüklenecek veri setinin alt kümesi. Örnek: \"sst2\" (GLUE için).\n\n- **`data_dir`**:\n  - Veri dosyalarının bulunduğu dizin.\n\n- **`data_files`**:\n  - Yüklenecek veri dosyaları.\n\n- **`split`**:\n  - Veri setinin bölünmesi (örneğin \"train\", \"test\").\n\n- **`cache_dir`**:\n  - Verinin önbelleğe alınacağı dizin.\n\n- **`features`**:\n  - Özelliklerin açıkça belirtildiği yer.\n\n- **`download_config`**:\n  - İndirme yapılandırma ayarları.\n\n- **`download_mode`**:\n  - İndirme modu: \"reuse_dataset_if_exists\", \"reuse_cache_if_exists\", \"force_redownload\".\n\n- **`verification_mode`**:\n  - Veri setinin doğrulama modu.\n\n- **`ignore_verifications`**:\n  - Artık kullanılmıyor, doğrulamaları atlamak için.\n\n- **`keep_in_memory`**:\n  - Eğer True ise, veri seti bellekte tutulur.\n\n- **`save_infos`**:\n  - Eğer True ise, veri seti bilgileri kaydedilir.\n\n- **`revision`**:\n  - Yüklenecek veri setinin versiyonu veya commit ID'si.\n\n- **`token`**:\n  - Private veri setleri için kullanılır, bir token sağlar.\n\n- **`use_auth_token`**:\n  - Artık kullanılmıyor, oturum açma token'ı için.\n\n- **`task`**:\n  - Artık kullanılmıyor, veri seti yükleme görevini belirtmek için.\n\n- **`streaming`**:\n  - Eğer True ise, veri seti akış modunda yüklenir.\n\n- **`num_proc`**:\n  - Çok işlemcili veri işleme için işlemci sayısı.\n\n- **`storage_options`**:\n  - Depolama seçenekleri.\n\n- **`trust_remote_code`**:\n  - Eğer True ise, uzaktan kod çalıştırmaya izin verir.\n\n- **`**config_kwargs`**:\n  - Diğer ek yapılandırma argümanları.\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T13:40:46.289172Z","iopub.execute_input":"2024-06-18T13:40:46.290493Z","iopub.status.idle":"2024-06-18T13:40:46.372076Z","shell.execute_reply.started":"2024-06-18T13:40:46.290449Z","shell.execute_reply":"2024-06-18T13:40:46.370878Z"}}},{"cell_type":"code","source":"# Veri setini yükleme\ndataset = load_dataset(path=\"stanfordnlp/imdb\", split='train')\n\ndataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = dataset.to_pandas()\n\ndf.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_labels = len(df['label'].unique())\n\ndf['label'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data, _ = train_test_split(df, train_size=0.1, stratify=df['label'])\ntest_data, _ = train_test_split(df, test_size=0.02, stratify=df['label'])\n\ntrain_data = Dataset.from_pandas(train_data)\ntest_data = Dataset.from_pandas(test_data)\n\ntype(train_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model_name = 'distilbert-base-uncased'\n\n# Tokenizer yükleme       \ntokenizer = AutoTokenizer.from_pretrained(base_model_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 🤗 Hugging Face Tokenizer Kütüphanesi\n\n### Parametreler\n\n- **`text`**:\n  - Tokenize edilecek metin veya metinlerin listesi.\n\n- **`text_pair`**:\n  - İkinci bir metin veya metinlerin listesi, çift metinli modeller için kullanılır.\n\n- **`text_target`**:\n  - Hedef metin veya metinlerin listesi (genellikle seq2seq modelleri için kullanılır).\n\n- **`text_pair_target`**:\n  - Hedef ikinci metin veya metinlerin listesi, çift metinli modeller için kullanılır.\n\n- **`add_special_tokens`**:\n  - Özel tokenler ekler (örneğin [CLS], [SEP]). True olması, modeli daha iyi performans gösterir.\n\n- **`padding`**:\n  - Padding stratejisi: True, False, \"longest\", \"max_length\".\n\n- **`truncation`**:\n  - Kesme stratejisi: True, False, \"longest_first\", \"only_first\".\n\n- **`max_length`**:\n  - Maksimum token sayısı. Yüksek değerler daha fazla bilgi taşır ama daha fazla bellek kullanır.\n\n- **`stride`**:\n  - Kesme sırasında kayma boyutu. Uzun metinler için daha küçük değerler kullanışlı olabilir.\n\n- **`is_split_into_words`**:\n  - Eğer True ise, metin kelimelere bölünmüş olarak kabul edilir.\n\n- **`pad_to_multiple_of`**:\n  - Padding boyutunun bir katı olacak şekilde padding ekler.\n\n- **`return_tensors`**:\n  - Döndürülecek tensör tipi: 'pt', 'tf', 'np'.\n\n- **`return_token_type_ids`**:\n  - Eğer True ise, token tipi ID'lerini döndürür.\n\n- **`return_attention_mask`**:\n  - Eğer True ise, attention maskelerini döndürür.\n\n- **`return_overflowing_tokens`**:\n  - Eğer True ise, taşan tokenleri döndürür.\n\n- **`return_special_tokens_mask`**:\n  - Eğer True ise, özel token maskesini döndürür.\n\n- **`return_offsets_mapping`**:\n  - Eğer True ise, offset mapping döndürür.\n\n- **`return_length`**:\n  - Eğer True ise, token uzunluklarını döndürür.\n\n- **`verbose`**:\n  - Eğer True ise, işlem hakkında daha fazla bilgi verir.\n\n- **`**kwargs`**:\n  - Diğer ek argümanlar.\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T13:27:37.261162Z","iopub.execute_input":"2024-06-18T13:27:37.261550Z","iopub.status.idle":"2024-06-18T13:27:37.282741Z","shell.execute_reply.started":"2024-06-18T13:27:37.261519Z","shell.execute_reply":"2024-06-18T13:27:37.281786Z"}}},{"cell_type":"code","source":"def text_tokenizer(text):\n    \"\"\"\n    text_tokenizer: Bu fonksiyon verilen metni tokenize eder.\n\n    Args:\n        text: str: Tokenize edilecek metin\n    \"\"\"\n    return tokenizer(\n        text['text'], \n        padding='max_length',\n        truncation=True\n    )\n\ntrain_data = train_data.map(\n    text_tokenizer, \n    batched=True\n)\n\ntest_data = test_data.map(\n    text_tokenizer, \n    batched=True\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 🤗 Hugging Face TrainingArguments Kütüphanesi\n\n### Parametreler\n\n- **`output_dir`**:\n  - Eğitim sırasında ve sonrasında sonuçların kaydedileceği dizin.\n\n- **`overwrite_output_dir`**:\n  - Eğer True ise, mevcut `output_dir` içeriğini üzerine yazar.\n\n- **`do_train`**:\n  - Eğitim işleminin yapılıp yapılmayacağını belirtir.\n\n- **`do_eval`**:\n  - Değerlendirme işleminin yapılıp yapılmayacağını belirtir.\n\n- **`do_predict`**:\n  - Tahmin işleminin yapılıp yapılmayacağını belirtir.\n\n- **`eval_strategy`**:\n  - Değerlendirme stratejisi: 'no', 'steps' veya 'epoch'.\n\n- **`prediction_loss_only`**:\n  - Eğer True ise, sadece kayıp hesaplanır, tahminler döndürülmez.\n\n- **`per_device_train_batch_size`**:\n  - Her bir cihaz (GPU/CPU) için eğitim batch boyutu.\n\n- **`per_device_eval_batch_size`**:\n  - Her bir cihaz (GPU/CPU) için değerlendirme batch boyutu.\n\n- **`gradient_accumulation_steps`**:\n  - Gradient biriktirme adımları. Yüksek değerler bellek kullanımını azaltır ama eğitim süresini uzatır.\n\n- **`eval_accumulation_steps`**:\n  - Değerlendirme biriktirme adımları. Yüksek değerler bellek kullanımını azaltır ama değerlendirme süresini uzatır.\n\n- **`eval_delay`**:\n  - Eğitim başladıktan sonra ilk değerlendirmenin yapılacağı adım sayısı.\n\n- **`learning_rate`**:\n  - Öğrenme oranı. Yüksek değerler daha hızlı öğrenir ama aşırı öğrenmeye (overfitting) yol açabilir.\n\n- **`weight_decay`**:\n  - Ağırlıkların küçülme oranı. Yüksek değerler modelin genelleme yeteneğini artırabilir ama öğrenme yavaşlar.\n\n- **`adam_beta1`**:\n  - Adam optimizasyon algoritması için beta1 parametresi.\n\n- **`adam_beta2`**:\n  - Adam optimizasyon algoritması için beta2 parametresi.\n\n- **`adam_epsilon`**:\n  - Adam optimizasyon algoritması için epsilon parametresi.\n\n- **`max_grad_norm`**:\n  - Gradientlerin maksimum normu. Büyük değerler modelin stabilitesini artırabilir.\n\n- **`num_train_epochs`**:\n  - Eğitim için epoch sayısı. Yüksek değerler daha fazla öğrenme sağlar ama aşırı öğrenmeye yol açabilir.\n\n- **`max_steps`**:\n  - Maksimum eğitim adım sayısı. -1 ise, tüm epoch'lar tamamlanır.\n\n- **`lr_scheduler_type`**:\n  - Öğrenme oranı zamanlayıcı tipi.\n\n- **`lr_scheduler_kwargs`**:\n  - Öğrenme oranı zamanlayıcısı için ek parametreler.\n\n- **`warmup_ratio`**:\n  - Öğrenme oranı ısınma oranı. Yüksek değerler başlangıçta daha yavaş öğrenme sağlar.\n\n- **`warmup_steps`**:\n  - Öğrenme oranı ısınma adım sayısı. Yüksek değerler başlangıçta daha yavaş öğrenme sağlar.\n\n- **`log_level`**:\n  - Log seviyesi. 'passive', 'info', 'warning', 'error' veya 'critical'.\n\n- **`log_level_replica`**:\n  - Çoklu GPU eğitiminde log seviyesi.\n\n- **`log_on_each_node`**:\n  - Çoklu node eğitiminde her node için loglama yapılır.\n\n- **`logging_dir`**:\n  - TensorBoard logları için dizin.\n\n- **`logging_strategy`**:\n  - Loglama stratejisi: 'no', 'steps' veya 'epoch'.\n\n- **`logging_first_step`**:\n  - Eğer True ise, ilk adımda loglama yapılır.\n\n- **`logging_steps`**:\n  - Kaç adımda bir loglama yapılacağı.\n\n- **`logging_nan_inf_filter`**:\n  - Eğer True ise, NaN ve sonsuz değerler loglanmaz.\n\n- **`save_strategy`**:\n  - Modelin kaydedilme stratejisi: 'no', 'steps' veya 'epoch'.\n\n- **`save_steps`**:\n  - Kaç adımda bir modelin kaydedileceği.\n\n- **`save_total_limit`**:\n  - Maksimum kaç model kaydedileceği.\n\n- **`save_safetensors`**:\n  - Modelin güvenli tensör formatında kaydedilip kaydedilmeyeceği.\n\n- **`save_on_each_node`**:\n  - Eğer True ise, her node'da model kaydedilir.\n\n- **`save_only_model`**:\n  - Eğer True ise, sadece model kaydedilir, optimizer ve lr scheduler kaydedilmez.\n\n- **`restore_callback_states_from_checkpoint`**:\n  - Callback durumlarının checkpoint'ten geri yüklenip yüklenmeyeceği.\n\n- **`no_cuda`**:\n  - Eğer True ise, GPU kullanılmaz.\n\n- **`use_cpu`**:\n  - Eğer True ise, CPU kullanılır.\n\n- **`use_mps_device`**:\n  - Eğer True ise, MacOS Metal Performance Shaders kullanılır.\n\n- **`seed`**:\n  - Rastgelelik için seed değeri.\n\n- **`data_seed`**:\n  - Veri yükleme için seed değeri.\n\n- **`jit_mode_eval`**:\n  - Eğer True ise, PyTorch JIT modu kullanılır.\n\n- **`use_ipex`**:\n  - Eğer True ise, Intel Extension for PyTorch kullanılır.\n\n- **`bf16`**:\n  - Eğer True ise, bfloat16 kullanılır.\n\n- **`fp16`**:\n  - Eğer True ise, float16 kullanılır.\n\n- **`fp16_opt_level`**:\n  - float16 optimizasyon seviyesi.\n\n- **`half_precision_backend`**:\n  - Yarı hassasiyet arka ucu: 'auto', 'amp' veya 'apex'.\n\n- **`bf16_full_eval`**:\n  - Eğer True ise, bfloat16 tam değerlendirme yapılır.\n\n- **`fp16_full_eval`**:\n  - Eğer True ise, float16 tam değerlendirme yapılır.\n\n- **`tf32`**:\n  - Eğer True ise, TensorFloat-32 kullanılır.\n\n- **`local_rank`**:\n  - Çoklu GPU eğitiminde lokal rank.\n\n- **`ddp_backend`**:\n  - DDP backend tipi: 'nccl', 'gloo', 'mpi'.\n\n- **`tpu_num_cores`**:\n  - TPU çekirdek sayısı.\n\n- **`tpu_metrics_debug`**:\n  - TPU metriklerinin debug bilgilerini içerir.\n\n- **`debug`**:\n  - Debug seçeneği: 'underflow_overflow', 'poor_optimization'.\n\n- **`dataloader_drop_last`**:\n  - Eğer True ise, dataloader son batch'i düşürür.\n\n- **`eval_steps`**:\n  - Değerlendirme adım sayısı.\n\n- **`dataloader_num_workers`**:\n  - Dataloader için çalışan sayısı. Yüksek değerler hız artırır ama daha fazla bellek kullanır.\n\n- **`dataloader_prefetch_factor`**:\n  - Dataloader için prefetch faktörü. Yüksek değerler hız artırır ama daha fazla bellek kullanır.\n\n- **`past_index`**:\n  - Geçmiş index.\n\n- **`run_name`**:\n  - Çalışma ismi.\n\n- **`disable_tqdm`**:\n  - Eğer True ise, tqdm progress bar devre dışı bırakılır.\n\n- **`remove_unused_columns`**:\n  - Eğer True ise, kullanılmayan sütunlar veri setinden kaldırılır.\n\n- **`label_names`**:\n  - Label isimleri.\n\n- **`load_best_model_at_end`**:\n  - Eğitim sonunda en iyi modelin yüklenip yüklenmeyeceği.\n\n- **`metric_for_best_model`**:\n  - En iyi modelin seçilmesi için kullanılacak metrik.\n\n- **`greater_is_better`**:\n  - Eğer True ise, metriklerde yüksek değerler daha iyi olarak kabul edilir.\n\n- **`ignore_data_skip`**:\n  - Eğer True ise, veri atlamaları göz ardı edilir.\n\n- **`fsdp`**:\n  - Fully Sharded Data Parallel ayarları.\n\n- **`fsdp_min_num_params`**:\n  - Fully Sharded Data Parallel için minimum parametre sayısı.\n\n- **`fsdp_config`**:\n  - Fully Sharded Data Parallel için ek ayarlar.\n\n- **`fsdp_transformer_layer_cls_to_wrap`**:\n  - Fully Sharded Data Parallel için transformer layer sınıfı.\n\n- **`accelerator_config`**:\n  - Accelerator için ek ayarlar.\n\n- **`deepspeed`**:\n  - DeepSpeed yapılandırması.\n\n- **`label_smoothing_factor`**:\n  - Label smoothing faktörü.\n\n- **`optim`**:\n  - Optimizasyon algoritması.\n\n- **`optim_args`**:\n  - Optimizasyon algoritması için ek argümanlar.\n\n- **`adafactor`**:\n  - Eğer True ise, Adafactor optimizasyon algoritması kullanılır.\n\n- **`group_by_length`**:\n  - Eğer True ise, input uzunluğuna göre gruplanır.\n\n- **`length_column_name`**:\n  - Uzunluk sütunu ismi.\n\n- **`report_to`**:\n  - Raporlama platformları (örneğin 'wandb').\n\n- **`ddp_find_unused_parameters`**:\n  - DDP'de kullanılmayan parametrelerin bulunması.\n\n- **`ddp_bucket_cap_mb`**:\n  - DDP bucket kapasitesi.\n\n- **`ddp_broadcast_buffers`**:\n  - DDP broadcast buffer'ları.\n\n- **`dataloader_pin_memory`**:\n  - Dataloader için bellek pinleme.\n\n- **`dataloader_persistent_workers`**:\n  - Dataloader için kalıcı çalışanlar.\n\n- **`skip_memory_metrics`**:\n  - Eğer True ise, bellek metrikleri atlanır.\n\n- **`use_legacy_prediction_loop`**:\n  - Eğer True ise, eski tahmin döngüsü kullanılır.\n\n- **`push_to_hub`**:\n  - Eğer True ise, model Hugging Face Hub'a itilir.\n\n- **`resume_from_checkpoint`**:\n  - Checkpoint'ten devam edilir.\n\n- **`hub_model_id`**:\n  - Hugging Face Hub model ID.\n\n- **`hub_strategy`**:\n  - Hub stratejisi.\n\n- **`hub_token`**:\n  - Hugging Face Hub token.\n\n- **`hub_private_repo`**:\n  - Eğer True ise, özel repo kullanılır.\n\n- **`hub_always_push`**:\n  - Eğer True ise, her zaman Hub'a itilir.\n\n- **`gradient_checkpointing`**:\n  - Eğer True ise, gradient checkpointing yapılır.\n\n- **`gradient_checkpointing_kwargs`**:\n  - Gradient checkpointing için ek argümanlar.\n\n- **`include_inputs_for_metrics`**:\n  - Eğer True ise, değerlendirme metrikleri için inputlar da dahil edilir.\n\n- **`eval_do_concat_batches`**:\n  - Eğer True ise, değerlendirme batch'leri birleştirilir.\n\n- **`fp16_backend`**:\n  - float16 arka ucu.\n\n- **`evaluation_strategy`**:\n  - Değerlendirme stratejisi: 'no', 'steps' veya 'epoch'.\n\n- **`push_to_hub_model_id`**:\n  - Hub model ID.\n\n- **`push_to_hub_organization`**:\n  - Hub organizasyon ID.\n\n- **`push_to_hub_token`**:\n  - Hub token.\n\n- **`mp_parameters`**:\n  - Model paralel parametreler.\n\n- **`auto_find_batch_size`**:\n  - Eğer True ise, batch boyutu otomatik bulunur.\n\n- **`full_determinism`**:\n  - Eğer True ise, deterministik eğitim yapılır.\n\n- **`torchdynamo`**:\n  - TorchDynamo kullanımı.\n\n- **`ray_scope`**:\n  - Ray scope.\n\n- **`ddp_timeout`**:\n  - DDP timeout süresi.\n\n- **`torch_compile`**:\n  - Eğer True ise, Torch compile kullanılır.\n\n- **`torch_compile_backend`**:\n  - Torch compile backend.\n\n- **`torch_compile_mode`**:\n  - Torch compile modu.\n\n- **`dispatch_batches`**:\n  - Batch dispatching.\n\n- **`split_batches`**:\n  - Batch splitting.\n\n- **`include_tokens_per_second`**:\n  - Eğer True ise, saniye başına token sayısı dahil edilir.\n\n- **`include_num_input_tokens_seen`**:\n  - Eğer True ise, görülen input token sayısı dahil edilir.\n\n- **`neftune_noise_alpha`**:\n  - Neptune noise alpha.\n\n- **`optim_target_modules`**:\n  - Optimizasyon hedef modüller.\n\n- **`batch_eval_metrics`**:\n  - Eğer True ise, batch değerlendirme metrikleri hesaplanır.\n","metadata":{}},{"cell_type":"code","source":"# Modeli yükleme        \nmodel = AutoModelForSequenceClassification.from_pretrained(base_model_name, num_labels=num_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TrainingArguments sınıfı ile modelin eğitim parametrelerini belirleme\ntraining_args = TrainingArguments(\n    output_dir=\"./results\", \n    evaluation_strategy=\"steps\", \n    save_strategy=\"steps\",  \n    learning_rate=2e-5, \n    per_device_train_batch_size=8,  \n    per_device_eval_batch_size=8,  \n    num_train_epochs=1, \n    weight_decay=0.01, \n    logging_dir='./logs',\n    logging_steps=10,  \n    save_steps=10,\n    save_total_limit=2,  \n    load_best_model_at_end=True,  \n    metric_for_best_model=\"accuracy\", \n    greater_is_better=True,  \n    do_train=True,  \n    do_eval=True,  \n    report_to=\"none\"  \n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(p):\n    \"\"\"\n    compute_metrics: Bu fonksiyon modelin performansını değerlendirmek için kullanılır.\n\n    Args:\n        p: Trainer: Trainer sınıfı, modelin tahminlerini ve etiketlerini içerir.\n    \"\"\"\n    preds = np.argmax(p.predictions, axis=1)\n    labels = p.label_ids\n\n    accuracy = accuracy_score(labels, preds)\n    precision = precision_score(labels, preds, average='weighted')\n    recall = recall_score(labels, preds, average='weighted')\n    f1 = f1_score(labels, preds, average='weighted')\n\n    return {\n        \"accuracy\": accuracy,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1\": f1\n    }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 🤗 Hugging Face Trainer Kütüphanesi\n\n### Parametreler\n\n- **`model`**:\n  - Eğitim ve değerlendirme için kullanılacak model.\n\n- **`args`**:\n  - Eğitim argümanları, `TrainingArguments` sınıfı ile oluşturulur.\n\n- **`data_collator`**:\n  - Veriyi toplamak için kullanılan data collator.\n\n- **`train_dataset`**:\n  - Eğitim için kullanılacak veri seti.\n\n- **`eval_dataset`**:\n  - Değerlendirme için kullanılacak veri seti.\n\n- **`tokenizer`**:\n  - Metin verilerini modelin anlayabileceği sayısal değerlere dönüştürür.\n\n- **`model_init`**:\n  - Modelin başlatılması için kullanılacak fonksiyon.\n\n- **`compute_metrics`**:\n  - Değerlendirme metriklerini hesaplamak için kullanılacak fonksiyon.\n\n- **`callbacks`**:\n  - Eğitim sürecini izlemek ve kontrol etmek için kullanılacak callback listesi.\n\n- **`optimizers`**:\n  - Optimizasyon algoritması ve öğrenme oranı zamanlayıcısı.\n\n- **`preprocess_logits_for_metrics`**:\n  - Metrik hesaplama için logits'i ön işleme fonksiyonu.\n","metadata":{}},{"cell_type":"code","source":"# Trainer sınıfı ile modelin eğitim için hazırlanması\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=test_data, \n    compute_metrics=compute_metrics\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Modelin eğitilmesi\ntrainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}