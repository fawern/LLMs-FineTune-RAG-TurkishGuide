{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom transformers import TrainingArguments, Trainer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ğŸ¤— Hugging Face Datasets KÃ¼tÃ¼phanesi\n\n### Parametreler\n\n- **`path`**:\n  - YÃ¼klenecek veri setinin yolu veya ismi. Ã–rnek: \"imdb\", \"glue\".\n\n- **`name`**:\n  - YÃ¼klenecek veri setinin alt kÃ¼mesi. Ã–rnek: \"sst2\" (GLUE iÃ§in).\n\n- **`data_dir`**:\n  - Veri dosyalarÄ±nÄ±n bulunduÄŸu dizin.\n\n- **`data_files`**:\n  - YÃ¼klenecek veri dosyalarÄ±.\n\n- **`split`**:\n  - Veri setinin bÃ¶lÃ¼nmesi (Ã¶rneÄŸin \"train\", \"test\").\n\n- **`cache_dir`**:\n  - Verinin Ã¶nbelleÄŸe alÄ±nacaÄŸÄ± dizin.\n\n- **`features`**:\n  - Ã–zelliklerin aÃ§Ä±kÃ§a belirtildiÄŸi yer.\n\n- **`download_config`**:\n  - Ä°ndirme yapÄ±landÄ±rma ayarlarÄ±.\n\n- **`download_mode`**:\n  - Ä°ndirme modu: \"reuse_dataset_if_exists\", \"reuse_cache_if_exists\", \"force_redownload\".\n\n- **`verification_mode`**:\n  - Veri setinin doÄŸrulama modu.\n\n- **`ignore_verifications`**:\n  - ArtÄ±k kullanÄ±lmÄ±yor, doÄŸrulamalarÄ± atlamak iÃ§in.\n\n- **`keep_in_memory`**:\n  - EÄŸer True ise, veri seti bellekte tutulur.\n\n- **`save_infos`**:\n  - EÄŸer True ise, veri seti bilgileri kaydedilir.\n\n- **`revision`**:\n  - YÃ¼klenecek veri setinin versiyonu veya commit ID'si.\n\n- **`token`**:\n  - Private veri setleri iÃ§in kullanÄ±lÄ±r, bir token saÄŸlar.\n\n- **`use_auth_token`**:\n  - ArtÄ±k kullanÄ±lmÄ±yor, oturum aÃ§ma token'Ä± iÃ§in.\n\n- **`task`**:\n  - ArtÄ±k kullanÄ±lmÄ±yor, veri seti yÃ¼kleme gÃ¶revini belirtmek iÃ§in.\n\n- **`streaming`**:\n  - EÄŸer True ise, veri seti akÄ±ÅŸ modunda yÃ¼klenir.\n\n- **`num_proc`**:\n  - Ã‡ok iÅŸlemcili veri iÅŸleme iÃ§in iÅŸlemci sayÄ±sÄ±.\n\n- **`storage_options`**:\n  - Depolama seÃ§enekleri.\n\n- **`trust_remote_code`**:\n  - EÄŸer True ise, uzaktan kod Ã§alÄ±ÅŸtÄ±rmaya izin verir.\n\n- **`**config_kwargs`**:\n  - DiÄŸer ek yapÄ±landÄ±rma argÃ¼manlarÄ±.\n","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset('Trelis/tiny-shakespeare', split='train')\n\ndataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ğŸ¤— Hugging Face Tokenizer KÃ¼tÃ¼phanesi\n\n### Parametreler\n\n- **`text`**:\n  - Tokenize edilecek metin veya metinlerin listesi.\n\n- **`text_pair`**:\n  - Ä°kinci bir metin veya metinlerin listesi, Ã§ift metinli modeller iÃ§in kullanÄ±lÄ±r.\n\n- **`text_target`**:\n  - Hedef metin veya metinlerin listesi (genellikle seq2seq modelleri iÃ§in kullanÄ±lÄ±r).\n\n- **`text_pair_target`**:\n  - Hedef ikinci metin veya metinlerin listesi, Ã§ift metinli modeller iÃ§in kullanÄ±lÄ±r.\n\n- **`add_special_tokens`**:\n  - Ã–zel tokenler ekler (Ã¶rneÄŸin [CLS], [SEP]). True olmasÄ±, modeli daha iyi performans gÃ¶sterir.\n\n- **`padding`**:\n  - Padding stratejisi: True, False, \"longest\", \"max_length\".\n\n- **`truncation`**:\n  - Kesme stratejisi: True, False, \"longest_first\", \"only_first\".\n\n- **`max_length`**:\n  - Maksimum token sayÄ±sÄ±. YÃ¼ksek deÄŸerler daha fazla bilgi taÅŸÄ±r ama daha fazla bellek kullanÄ±r.\n\n- **`stride`**:\n  - Kesme sÄ±rasÄ±nda kayma boyutu. Uzun metinler iÃ§in daha kÃ¼Ã§Ã¼k deÄŸerler kullanÄ±ÅŸlÄ± olabilir.\n\n- **`is_split_into_words`**:\n  - EÄŸer True ise, metin kelimelere bÃ¶lÃ¼nmÃ¼ÅŸ olarak kabul edilir.\n\n- **`pad_to_multiple_of`**:\n  - Padding boyutunun bir katÄ± olacak ÅŸekilde padding ekler.\n\n- **`return_tensors`**:\n  - DÃ¶ndÃ¼rÃ¼lecek tensÃ¶r tipi: 'pt', 'tf', 'np'.\n\n- **`return_token_type_ids`**:\n  - EÄŸer True ise, token tipi ID'lerini dÃ¶ndÃ¼rÃ¼r.\n\n- **`return_attention_mask`**:\n  - EÄŸer True ise, attention maskelerini dÃ¶ndÃ¼rÃ¼r.\n\n- **`return_overflowing_tokens`**:\n  - EÄŸer True ise, taÅŸan tokenleri dÃ¶ndÃ¼rÃ¼r.\n\n- **`return_special_tokens_mask`**:\n  - EÄŸer True ise, Ã¶zel token maskesini dÃ¶ndÃ¼rÃ¼r.\n\n- **`return_offsets_mapping`**:\n  - EÄŸer True ise, offset mapping dÃ¶ndÃ¼rÃ¼r.\n\n- **`return_length`**:\n  - EÄŸer True ise, token uzunluklarÄ±nÄ± dÃ¶ndÃ¼rÃ¼r.\n\n- **`verbose`**:\n  - EÄŸer True ise, iÅŸlem hakkÄ±nda daha fazla bilgi verir.\n\n- **`**kwargs`**:\n  - DiÄŸer ek argÃ¼manlar.\n","metadata":{}},{"cell_type":"code","source":"base_model_name = \"openai-community/gpt2\"\n\ntokenizer = AutoTokenizer.from_pretrained(base_model_name)\n\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def text_tokenizer(text):\n    return tokenizer(\n        text['text'], \n        max_length=128, \n        truncation=True, \n        padding='max_length', \n        return_tensors='pt'\n    )\n\ntrain_data = dataset['train'].map(text_tokenizer, batched=True)\ntest_data = dataset['test'].map(text_tokenizer, batched=True)\nval_data = dataset['validation'].map(text_tokenizer, batched=True)\n\ntrain_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(base_model_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ğŸ¤— Hugging Face TrainingArguments KÃ¼tÃ¼phanesi\n\n### Parametreler\n\n- **`output_dir`**:\n  - EÄŸitim sÄ±rasÄ±nda ve sonrasÄ±nda sonuÃ§larÄ±n kaydedileceÄŸi dizin.\n\n- **`overwrite_output_dir`**:\n  - EÄŸer True ise, mevcut `output_dir` iÃ§eriÄŸini Ã¼zerine yazar.\n\n- **`do_train`**:\n  - EÄŸitim iÅŸleminin yapÄ±lÄ±p yapÄ±lmayacaÄŸÄ±nÄ± belirtir.\n\n- **`do_eval`**:\n  - DeÄŸerlendirme iÅŸleminin yapÄ±lÄ±p yapÄ±lmayacaÄŸÄ±nÄ± belirtir.\n\n- **`do_predict`**:\n  - Tahmin iÅŸleminin yapÄ±lÄ±p yapÄ±lmayacaÄŸÄ±nÄ± belirtir.\n\n- **`eval_strategy`**:\n  - DeÄŸerlendirme stratejisi: 'no', 'steps' veya 'epoch'.\n\n- **`prediction_loss_only`**:\n  - EÄŸer True ise, sadece kayÄ±p hesaplanÄ±r, tahminler dÃ¶ndÃ¼rÃ¼lmez.\n\n- **`per_device_train_batch_size`**:\n  - Her bir cihaz (GPU/CPU) iÃ§in eÄŸitim batch boyutu.\n\n- **`per_device_eval_batch_size`**:\n  - Her bir cihaz (GPU/CPU) iÃ§in deÄŸerlendirme batch boyutu.\n\n- **`gradient_accumulation_steps`**:\n  - Gradient biriktirme adÄ±mlarÄ±. YÃ¼ksek deÄŸerler bellek kullanÄ±mÄ±nÄ± azaltÄ±r ama eÄŸitim sÃ¼resini uzatÄ±r.\n\n- **`eval_accumulation_steps`**:\n  - DeÄŸerlendirme biriktirme adÄ±mlarÄ±. YÃ¼ksek deÄŸerler bellek kullanÄ±mÄ±nÄ± azaltÄ±r ama deÄŸerlendirme sÃ¼resini uzatÄ±r.\n\n- **`eval_delay`**:\n  - EÄŸitim baÅŸladÄ±ktan sonra ilk deÄŸerlendirmenin yapÄ±lacaÄŸÄ± adÄ±m sayÄ±sÄ±.\n\n- **`learning_rate`**:\n  - Ã–ÄŸrenme oranÄ±. YÃ¼ksek deÄŸerler daha hÄ±zlÄ± Ã¶ÄŸrenir ama aÅŸÄ±rÄ± Ã¶ÄŸrenmeye (overfitting) yol aÃ§abilir.\n\n- **`weight_decay`**:\n  - AÄŸÄ±rlÄ±klarÄ±n kÃ¼Ã§Ã¼lme oranÄ±. YÃ¼ksek deÄŸerler modelin genelleme yeteneÄŸini artÄ±rabilir ama Ã¶ÄŸrenme yavaÅŸlar.\n\n- **`adam_beta1`**:\n  - Adam optimizasyon algoritmasÄ± iÃ§in beta1 parametresi.\n\n- **`adam_beta2`**:\n  - Adam optimizasyon algoritmasÄ± iÃ§in beta2 parametresi.\n\n- **`adam_epsilon`**:\n  - Adam optimizasyon algoritmasÄ± iÃ§in epsilon parametresi.\n\n- **`max_grad_norm`**:\n  - Gradientlerin maksimum normu. BÃ¼yÃ¼k deÄŸerler modelin stabilitesini artÄ±rabilir.\n\n- **`num_train_epochs`**:\n  - EÄŸitim iÃ§in epoch sayÄ±sÄ±. YÃ¼ksek deÄŸerler daha fazla Ã¶ÄŸrenme saÄŸlar ama aÅŸÄ±rÄ± Ã¶ÄŸrenmeye yol aÃ§abilir.\n\n- **`max_steps`**:\n  - Maksimum eÄŸitim adÄ±m sayÄ±sÄ±. -1 ise, tÃ¼m epoch'lar tamamlanÄ±r.\n\n- **`lr_scheduler_type`**:\n  - Ã–ÄŸrenme oranÄ± zamanlayÄ±cÄ± tipi.\n\n- **`lr_scheduler_kwargs`**:\n  - Ã–ÄŸrenme oranÄ± zamanlayÄ±cÄ±sÄ± iÃ§in ek parametreler.\n\n- **`warmup_ratio`**:\n  - Ã–ÄŸrenme oranÄ± Ä±sÄ±nma oranÄ±. YÃ¼ksek deÄŸerler baÅŸlangÄ±Ã§ta daha yavaÅŸ Ã¶ÄŸrenme saÄŸlar.\n\n- **`warmup_steps`**:\n  - Ã–ÄŸrenme oranÄ± Ä±sÄ±nma adÄ±m sayÄ±sÄ±. YÃ¼ksek deÄŸerler baÅŸlangÄ±Ã§ta daha yavaÅŸ Ã¶ÄŸrenme saÄŸlar.\n\n- **`log_level`**:\n  - Log seviyesi. 'passive', 'info', 'warning', 'error' veya 'critical'.\n\n- **`log_level_replica`**:\n  - Ã‡oklu GPU eÄŸitiminde log seviyesi.\n\n- **`log_on_each_node`**:\n  - Ã‡oklu node eÄŸitiminde her node iÃ§in loglama yapÄ±lÄ±r.\n\n- **`logging_dir`**:\n  - TensorBoard loglarÄ± iÃ§in dizin.\n\n- **`logging_strategy`**:\n  - Loglama stratejisi: 'no', 'steps' veya 'epoch'.\n\n- **`logging_first_step`**:\n  - EÄŸer True ise, ilk adÄ±mda loglama yapÄ±lÄ±r.\n\n- **`logging_steps`**:\n  - KaÃ§ adÄ±mda bir loglama yapÄ±lacaÄŸÄ±.\n\n- **`logging_nan_inf_filter`**:\n  - EÄŸer True ise, NaN ve sonsuz deÄŸerler loglanmaz.\n\n- **`save_strategy`**:\n  - Modelin kaydedilme stratejisi: 'no', 'steps' veya 'epoch'.\n\n- **`save_steps`**:\n  - KaÃ§ adÄ±mda bir modelin kaydedileceÄŸi.\n\n- **`save_total_limit`**:\n  - Maksimum kaÃ§ model kaydedileceÄŸi.\n\n- **`save_safetensors`**:\n  - Modelin gÃ¼venli tensÃ¶r formatÄ±nda kaydedilip kaydedilmeyeceÄŸi.\n\n- **`save_on_each_node`**:\n  - EÄŸer True ise, her node'da model kaydedilir.\n\n- **`save_only_model`**:\n  - EÄŸer True ise, sadece model kaydedilir, optimizer ve lr scheduler kaydedilmez.\n\n- **`restore_callback_states_from_checkpoint`**:\n  - Callback durumlarÄ±nÄ±n checkpoint'ten geri yÃ¼klenip yÃ¼klenmeyeceÄŸi.\n\n- **`no_cuda`**:\n  - EÄŸer True ise, GPU kullanÄ±lmaz.\n\n- **`use_cpu`**:\n  - EÄŸer True ise, CPU kullanÄ±lÄ±r.\n\n- **`use_mps_device`**:\n  - EÄŸer True ise, MacOS Metal Performance Shaders kullanÄ±lÄ±r.\n\n- **`seed`**:\n  - Rastgelelik iÃ§in seed deÄŸeri.\n\n- **`data_seed`**:\n  - Veri yÃ¼kleme iÃ§in seed deÄŸeri.\n\n- **`jit_mode_eval`**:\n  - EÄŸer True ise, PyTorch JIT modu kullanÄ±lÄ±r.\n\n- **`use_ipex`**:\n  - EÄŸer True ise, Intel Extension for PyTorch kullanÄ±lÄ±r.\n\n- **`bf16`**:\n  - EÄŸer True ise, bfloat16 kullanÄ±lÄ±r.\n\n- **`fp16`**:\n  - EÄŸer True ise, float16 kullanÄ±lÄ±r.\n\n- **`fp16_opt_level`**:\n  - float16 optimizasyon seviyesi.\n\n- **`half_precision_backend`**:\n  - YarÄ± hassasiyet arka ucu: 'auto', 'amp' veya 'apex'.\n\n- **`bf16_full_eval`**:\n  - EÄŸer True ise, bfloat16 tam deÄŸerlendirme yapÄ±lÄ±r.\n\n- **`fp16_full_eval`**:\n  - EÄŸer True ise, float16 tam deÄŸerlendirme yapÄ±lÄ±r.\n\n- **`tf32`**:\n  - EÄŸer True ise, TensorFloat-32 kullanÄ±lÄ±r.\n\n- **`local_rank`**:\n  - Ã‡oklu GPU eÄŸitiminde lokal rank.\n\n- **`ddp_backend`**:\n  - DDP backend tipi: 'nccl', 'gloo', 'mpi'.\n\n- **`tpu_num_cores`**:\n  - TPU Ã§ekirdek sayÄ±sÄ±.\n\n- **`tpu_metrics_debug`**:\n  - TPU metriklerinin debug bilgilerini iÃ§erir.\n\n- **`debug`**:\n  - Debug seÃ§eneÄŸi: 'underflow_overflow', 'poor_optimization'.\n\n- **`dataloader_drop_last`**:\n  - EÄŸer True ise, dataloader son batch'i dÃ¼ÅŸÃ¼rÃ¼r.\n\n- **`eval_steps`**:\n  - DeÄŸerlendirme adÄ±m sayÄ±sÄ±.\n\n- **`dataloader_num_workers`**:\n  - Dataloader iÃ§in Ã§alÄ±ÅŸan sayÄ±sÄ±. YÃ¼ksek deÄŸerler hÄ±z artÄ±rÄ±r ama daha fazla bellek kullanÄ±r.\n\n- **`dataloader_prefetch_factor`**:\n  - Dataloader iÃ§in prefetch faktÃ¶rÃ¼. YÃ¼ksek deÄŸerler hÄ±z artÄ±rÄ±r ama daha fazla bellek kullanÄ±r.\n\n- **`past_index`**:\n  - GeÃ§miÅŸ index.\n\n- **`run_name`**:\n  - Ã‡alÄ±ÅŸma ismi.\n\n- **`disable_tqdm`**:\n  - EÄŸer True ise, tqdm progress bar devre dÄ±ÅŸÄ± bÄ±rakÄ±lÄ±r.\n\n- **`remove_unused_columns`**:\n  - EÄŸer True ise, kullanÄ±lmayan sÃ¼tunlar veri setinden kaldÄ±rÄ±lÄ±r.\n\n- **`label_names`**:\n  - Label isimleri.\n\n- **`load_best_model_at_end`**:\n  - EÄŸitim sonunda en iyi modelin yÃ¼klenip yÃ¼klenmeyeceÄŸi.\n\n- **`metric_for_best_model`**:\n  - En iyi modelin seÃ§ilmesi iÃ§in kullanÄ±lacak metrik.\n\n- **`greater_is_better`**:\n  - EÄŸer True ise, metriklerde yÃ¼ksek deÄŸerler daha iyi olarak kabul edilir.\n\n- **`ignore_data_skip`**:\n  - EÄŸer True ise, veri atlamalarÄ± gÃ¶z ardÄ± edilir.\n\n- **`fsdp`**:\n  - Fully Sharded Data Parallel ayarlarÄ±.\n\n- **`fsdp_min_num_params`**:\n  - Fully Sharded Data Parallel iÃ§in minimum parametre sayÄ±sÄ±.\n\n- **`fsdp_config`**:\n  - Fully Sharded Data Parallel iÃ§in ek ayarlar.\n\n- **`fsdp_transformer_layer_cls_to_wrap`**:\n  - Fully Sharded Data Parallel iÃ§in transformer layer sÄ±nÄ±fÄ±.\n\n- **`accelerator_config`**:\n  - Accelerator iÃ§in ek ayarlar.\n\n- **`deepspeed`**:\n  - DeepSpeed yapÄ±landÄ±rmasÄ±.\n\n- **`label_smoothing_factor`**:\n  - Label smoothing faktÃ¶rÃ¼.\n\n- **`optim`**:\n  - Optimizasyon algoritmasÄ±.\n\n- **`optim_args`**:\n  - Optimizasyon algoritmasÄ± iÃ§in ek argÃ¼manlar.\n\n- **`adafactor`**:\n  - EÄŸer True ise, Adafactor optimizasyon algoritmasÄ± kullanÄ±lÄ±r.\n\n- **`group_by_length`**:\n  - EÄŸer True ise, input uzunluÄŸuna gÃ¶re gruplanÄ±r.\n\n- **`length_column_name`**:\n  - Uzunluk sÃ¼tunu ismi.\n\n- **`report_to`**:\n  - Raporlama platformlarÄ± (Ã¶rneÄŸin 'wandb').\n\n- **`ddp_find_unused_parameters`**:\n  - DDP'de kullanÄ±lmayan parametrelerin bulunmasÄ±.\n\n- **`ddp_bucket_cap_mb`**:\n  - DDP bucket kapasitesi.\n\n- **`ddp_broadcast_buffers`**:\n  - DDP broadcast buffer'larÄ±.\n\n- **`dataloader_pin_memory`**:\n  - Dataloader iÃ§in bellek pinleme.\n\n- **`dataloader_persistent_workers`**:\n  - Dataloader iÃ§in kalÄ±cÄ± Ã§alÄ±ÅŸanlar.\n\n- **`skip_memory_metrics`**:\n  - EÄŸer True ise, bellek metrikleri atlanÄ±r.\n\n- **`use_legacy_prediction_loop`**:\n  - EÄŸer True ise, eski tahmin dÃ¶ngÃ¼sÃ¼ kullanÄ±lÄ±r.\n\n- **`push_to_hub`**:\n  - EÄŸer True ise, model Hugging Face Hub'a itilir.\n\n- **`resume_from_checkpoint`**:\n  - Checkpoint'ten devam edilir.\n\n- **`hub_model_id`**:\n  - Hugging Face Hub model ID.\n\n- **`hub_strategy`**:\n  - Hub stratejisi.\n\n- **`hub_token`**:\n  - Hugging Face Hub token.\n\n- **`hub_private_repo`**:\n  - EÄŸer True ise, Ã¶zel repo kullanÄ±lÄ±r.\n\n- **`hub_always_push`**:\n  - EÄŸer True ise, her zaman Hub'a itilir.\n\n- **`gradient_checkpointing`**:\n  - EÄŸer True ise, gradient checkpointing yapÄ±lÄ±r.\n\n- **`gradient_checkpointing_kwargs`**:\n  - Gradient checkpointing iÃ§in ek argÃ¼manlar.\n\n- **`include_inputs_for_metrics`**:\n  - EÄŸer True ise, deÄŸerlendirme metrikleri iÃ§in inputlar da dahil edilir.\n\n- **`eval_do_concat_batches`**:\n  - EÄŸer True ise, deÄŸerlendirme batch'leri birleÅŸtirilir.\n\n- **`fp16_backend`**:\n  - float16 arka ucu.\n\n- **`evaluation_strategy`**:\n  - DeÄŸerlendirme stratejisi: 'no', 'steps' veya 'epoch'.\n\n- **`push_to_hub_model_id`**:\n  - Hub model ID.\n\n- **`push_to_hub_organization`**:\n  - Hub organizasyon ID.\n\n- **`push_to_hub_token`**:\n  - Hub token.\n\n- **`mp_parameters`**:\n  - Model paralel parametreler.\n\n- **`auto_find_batch_size`**:\n  - EÄŸer True ise, batch boyutu otomatik bulunur.\n\n- **`full_determinism`**:\n  - EÄŸer True ise, deterministik eÄŸitim yapÄ±lÄ±r.\n\n- **`torchdynamo`**:\n  - TorchDynamo kullanÄ±mÄ±.\n\n- **`ray_scope`**:\n  - Ray scope.\n\n- **`ddp_timeout`**:\n  - DDP timeout sÃ¼resi.\n\n- **`torch_compile`**:\n  - EÄŸer True ise, Torch compile kullanÄ±lÄ±r.\n\n- **`torch_compile_backend`**:\n  - Torch compile backend.\n\n- **`torch_compile_mode`**:\n  - Torch compile modu.\n\n- **`dispatch_batches`**:\n  - Batch dispatching.\n\n- **`split_batches`**:\n  - Batch splitting.\n\n- **`include_tokens_per_second`**:\n  - EÄŸer True ise, saniye baÅŸÄ±na token sayÄ±sÄ± dahil edilir.\n\n- **`include_num_input_tokens_seen`**:\n  - EÄŸer True ise, gÃ¶rÃ¼len input token sayÄ±sÄ± dahil edilir.\n\n- **`neftune_noise_alpha`**:\n  - Neptune noise alpha.\n\n- **`optim_target_modules`**:\n  - Optimizasyon hedef modÃ¼ller.\n\n- **`batch_eval_metrics`**:\n  - EÄŸer True ise, batch deÄŸerlendirme metrikleri hesaplanÄ±r.\n","metadata":{}},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=1,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    hub_model_id='gpt2-wikitext-text-generation'\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ğŸ¤— Hugging Face Trainer KÃ¼tÃ¼phanesi\n\n### Parametreler\n\n- **`model`**:\n  - EÄŸitim ve deÄŸerlendirme iÃ§in kullanÄ±lacak model.\n\n- **`args`**:\n  - EÄŸitim argÃ¼manlarÄ±, `TrainingArguments` sÄ±nÄ±fÄ± ile oluÅŸturulur.\n\n- **`data_collator`**:\n  - Veriyi toplamak iÃ§in kullanÄ±lan data collator.\n\n- **`train_dataset`**:\n  - EÄŸitim iÃ§in kullanÄ±lacak veri seti.\n\n- **`eval_dataset`**:\n  - DeÄŸerlendirme iÃ§in kullanÄ±lacak veri seti.\n\n- **`tokenizer`**:\n  - Metin verilerini modelin anlayabileceÄŸi sayÄ±sal deÄŸerlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.\n\n- **`model_init`**:\n  - Modelin baÅŸlatÄ±lmasÄ± iÃ§in kullanÄ±lacak fonksiyon.\n\n- **`compute_metrics`**:\n  - DeÄŸerlendirme metriklerini hesaplamak iÃ§in kullanÄ±lacak fonksiyon.\n\n- **`callbacks`**:\n  - EÄŸitim sÃ¼recini izlemek ve kontrol etmek iÃ§in kullanÄ±lacak callback listesi.\n\n- **`optimizers`**:\n  - Optimizasyon algoritmasÄ± ve Ã¶ÄŸrenme oranÄ± zamanlayÄ±cÄ±sÄ±.\n\n- **`preprocess_logits_for_metrics`**:\n  - Metrik hesaplama iÃ§in logits'i Ã¶n iÅŸleme fonksiyonu.\n","metadata":{}},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=val_data\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ac4525a27cdcb34c068674c5fed00841eb0d9f4c","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\n# Login to Hugging Face account\nnotebook_login()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-06-19T18:05:28.944443Z","iopub.execute_input":"2024-06-19T18:05:28.944962Z","iopub.status.idle":"2024-06-19T18:05:29.248581Z","shell.execute_reply.started":"2024-06-19T18:05:28.944934Z","shell.execute_reply":"2024-06-19T18:05:29.247736Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f90182cd59294195bde8a458007b2587"}},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\nfrom datasets import load_dataset\n\n# Load dataset\ndataset = load_dataset('Trelis/tiny-shakespeare', split='train')\n\n# Load tokenizer and model\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\nmodel = GPT2LMHeadModel.from_pretrained('gpt2')\nmodel.to('cuda:0')\n# Set pad token\ntokenizer.pad_token = tokenizer.eos_token\n\n# Tokenize function\ndef tokenize_function(examples):\n    inputs = tokenizer(examples['Text'], truncation=True, padding='max_length', max_length=128)\n    inputs['labels'] = inputs['input_ids'].copy()\n    return inputs\n\n# Tokenize dataset\ntokenized_dataset = dataset.map(tokenize_function, batched=True)\n\n# Training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    evaluation_strategy=\"no\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=2,\n    do_eval=False,\n    num_train_epochs=1,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    push_to_hub=True,\n    hub_model_id='gpt2-wikitext-text-generation',\n    hub_strategy=\"end\",\n)\n\n# Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset,\n)\n\n# Train model\ntrainer.train()\n\n# Move model to device\nmodel = trainer.model\nmodel.to('cuda:0')\n\n# Input texts\ninput_texts = [\n    \"To be, or not to be, that is the question:\",\n    \"All the world's a stage, and all the men and women merely players:\"\n]\n\n# Generate text\ntext = input_texts[0]\ninputs = tokenizer(text, return_tensors='pt').to(device)\n\nprompt_text = \"Once upon a time\"\ninput_ids = tokenizer.encode(prompt_text, return_tensors='pt').to(device)\n\noutput = model.generate(\n    input_ids,\n    max_length=100,\n    num_return_sequences=1,\n    no_repeat_ngram_size=2,\n    early_stopping=True\n)\n\ngenerated_text = tokenizer.decode(output[0], skip_special_tokens=True)\nprint(generated_text)","metadata":{"execution":{"iopub.status.busy":"2024-06-19T18:05:35.981970Z","iopub.execute_input":"2024-06-19T18:05:35.982346Z","iopub.status.idle":"2024-06-19T18:06:46.166879Z","shell.execute_reply.started":"2024-06-19T18:05:35.982316Z","shell.execute_reply":"2024-06-19T18:06:46.165315Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-06-19 18:05:43.283789: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-19 18:05:43.283920: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-19 18:05:43.416533: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/497 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63c86b30fe9e4a78aed11663b7008baa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.22M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a62c16ae762d462f8060c16a82c1da3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/119k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3b305886911418580e4304dbae5e5c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/472 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57bcb8032f954c68b69a304c84565e15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/49 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a827b34349e14cc49611e675b3443a43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acd2cc5d85474d088c39578b67167776"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"800aa21e14a045f9b16c7cadf861368f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e727bb94aaf749f3969f8fea1e3e5277"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56a4b9900f34499fb43c3a6f5b04c360"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46b68173ae034c108d1405e4a2b76536"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3573273891824e28ba0031d57916e1e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f1eb1b8a044412fa3ebb9a653b4f031"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/472 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e111ec578d14c769c69853ec25a040e"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240619_180624-rjvfifv3</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/fawern/huggingface/runs/rjvfifv3' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/fawern/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/fawern/huggingface' target=\"_blank\">https://wandb.ai/fawern/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/fawern/huggingface/runs/rjvfifv3' target=\"_blank\">https://wandb.ai/fawern/huggingface/runs/rjvfifv3</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 47\u001b[0m\n\u001b[1;32m     40\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     41\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     42\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     43\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtokenized_dataset,\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Move model to device\u001b[39;00m\n\u001b[1;32m     50\u001b[0m model \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mmodel\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1876\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1873\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1874\u001b[0m     \u001b[38;5;66;03m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[1;32m   1875\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39mdisable_progress_bars()\n\u001b[0;32m-> 1876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1877\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1879\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1880\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1883\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2216\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2216\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2219\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2220\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2221\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2222\u001b[0m ):\n\u001b[1;32m   2223\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2224\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3241\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3238\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs)\n\u001b[1;32m   3240\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[0;32m-> 3241\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3244\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/memory.py:159\u001b[0m, in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Releases all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 159\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"],"ename":"RuntimeError","evalue":"CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}